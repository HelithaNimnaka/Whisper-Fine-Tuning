{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 20244,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.004762811964183654,
      "grad_norm": 0.980021595954895,
      "learning_rate": 0.0005,
      "loss": 2.1651,
      "step": 25
    },
    {
      "epoch": 0.009525623928367309,
      "grad_norm": 1.9137707948684692,
      "learning_rate": 0.001,
      "loss": 1.1787,
      "step": 50
    },
    {
      "epoch": 0.014288435892550962,
      "grad_norm": 1.1484131813049316,
      "learning_rate": 0.0009984073389819712,
      "loss": 0.648,
      "step": 75
    },
    {
      "epoch": 0.019051247856734618,
      "grad_norm": 1.1283599138259888,
      "learning_rate": 0.0009968146779639423,
      "loss": 0.4727,
      "step": 100
    },
    {
      "epoch": 0.02381405982091827,
      "grad_norm": 0.9064220190048218,
      "learning_rate": 0.0009952220169459132,
      "loss": 0.4163,
      "step": 125
    },
    {
      "epoch": 0.028576871785101925,
      "grad_norm": 0.8562195301055908,
      "learning_rate": 0.0009936293559278844,
      "loss": 0.4275,
      "step": 150
    },
    {
      "epoch": 0.03333968374928558,
      "grad_norm": 0.7423471212387085,
      "learning_rate": 0.0009920366949098553,
      "loss": 0.3862,
      "step": 175
    },
    {
      "epoch": 0.038102495713469235,
      "grad_norm": 0.7773299217224121,
      "learning_rate": 0.0009904440338918265,
      "loss": 0.3343,
      "step": 200
    },
    {
      "epoch": 0.042865307677652884,
      "grad_norm": 0.7770605087280273,
      "learning_rate": 0.0009888513728737976,
      "loss": 0.3452,
      "step": 225
    },
    {
      "epoch": 0.04762811964183654,
      "grad_norm": 0.6922643184661865,
      "learning_rate": 0.0009872587118557687,
      "loss": 0.3263,
      "step": 250
    },
    {
      "epoch": 0.052390931606020194,
      "grad_norm": 0.5657896399497986,
      "learning_rate": 0.0009856660508377397,
      "loss": 0.3165,
      "step": 275
    },
    {
      "epoch": 0.05715374357020385,
      "grad_norm": 0.7933101654052734,
      "learning_rate": 0.0009840733898197108,
      "loss": 0.3284,
      "step": 300
    },
    {
      "epoch": 0.061916555534387505,
      "grad_norm": 1.330878496170044,
      "learning_rate": 0.0009824807288016817,
      "loss": 0.3349,
      "step": 325
    },
    {
      "epoch": 0.06667936749857116,
      "grad_norm": 0.7755710482597351,
      "learning_rate": 0.000980888067783653,
      "loss": 0.3185,
      "step": 350
    },
    {
      "epoch": 0.07144217946275482,
      "grad_norm": 0.6191079616546631,
      "learning_rate": 0.000979295406765624,
      "loss": 0.3034,
      "step": 375
    },
    {
      "epoch": 0.07620499142693847,
      "grad_norm": 0.48071610927581787,
      "learning_rate": 0.0009777027457475952,
      "loss": 0.2792,
      "step": 400
    },
    {
      "epoch": 0.08096780339112211,
      "grad_norm": 0.5823918581008911,
      "learning_rate": 0.0009761100847295662,
      "loss": 0.3077,
      "step": 425
    },
    {
      "epoch": 0.08573061535530577,
      "grad_norm": 0.628765344619751,
      "learning_rate": 0.0009745174237115373,
      "loss": 0.2909,
      "step": 450
    },
    {
      "epoch": 0.09049342731948942,
      "grad_norm": 0.7154259085655212,
      "learning_rate": 0.0009729247626935084,
      "loss": 0.3008,
      "step": 475
    },
    {
      "epoch": 0.09525623928367308,
      "grad_norm": 0.5733907222747803,
      "learning_rate": 0.0009713321016754793,
      "loss": 0.3,
      "step": 500
    },
    {
      "epoch": 0.10001905124785673,
      "grad_norm": 0.5291111469268799,
      "learning_rate": 0.0009697394406574505,
      "loss": 0.2943,
      "step": 525
    },
    {
      "epoch": 0.10478186321204039,
      "grad_norm": 0.6086421012878418,
      "learning_rate": 0.0009681467796394215,
      "loss": 0.2863,
      "step": 550
    },
    {
      "epoch": 0.10954467517622404,
      "grad_norm": 0.6022641062736511,
      "learning_rate": 0.0009665541186213927,
      "loss": 0.2719,
      "step": 575
    },
    {
      "epoch": 0.1143074871404077,
      "grad_norm": 0.818818986415863,
      "learning_rate": 0.0009649614576033637,
      "loss": 0.2812,
      "step": 600
    },
    {
      "epoch": 0.11907029910459135,
      "grad_norm": 0.805573046207428,
      "learning_rate": 0.0009633687965853348,
      "loss": 0.3119,
      "step": 625
    },
    {
      "epoch": 0.12383311106877501,
      "grad_norm": 0.9937533140182495,
      "learning_rate": 0.0009617761355673059,
      "loss": 0.2868,
      "step": 650
    },
    {
      "epoch": 0.12859592303295866,
      "grad_norm": 0.659441351890564,
      "learning_rate": 0.0009601834745492769,
      "loss": 0.2718,
      "step": 675
    },
    {
      "epoch": 0.13335873499714232,
      "grad_norm": 4.831238746643066,
      "learning_rate": 0.000958590813531248,
      "loss": 0.2908,
      "step": 700
    },
    {
      "epoch": 0.13812154696132597,
      "grad_norm": 0.9643841981887817,
      "learning_rate": 0.0009569981525132191,
      "loss": 0.2848,
      "step": 725
    },
    {
      "epoch": 0.14288435892550963,
      "grad_norm": 0.8183784484863281,
      "learning_rate": 0.0009554054914951901,
      "loss": 0.2708,
      "step": 750
    },
    {
      "epoch": 0.14764717088969329,
      "grad_norm": 0.7190979719161987,
      "learning_rate": 0.0009538128304771613,
      "loss": 0.2564,
      "step": 775
    },
    {
      "epoch": 0.15240998285387694,
      "grad_norm": 0.5521268248558044,
      "learning_rate": 0.0009522201694591323,
      "loss": 0.2657,
      "step": 800
    },
    {
      "epoch": 0.1571727948180606,
      "grad_norm": 1.1423311233520508,
      "learning_rate": 0.0009506275084411035,
      "loss": 0.2684,
      "step": 825
    },
    {
      "epoch": 0.16193560678224422,
      "grad_norm": 0.5494915246963501,
      "learning_rate": 0.0009490348474230745,
      "loss": 0.2731,
      "step": 850
    },
    {
      "epoch": 0.16669841874642788,
      "grad_norm": 0.48756641149520874,
      "learning_rate": 0.0009474421864050455,
      "loss": 0.2447,
      "step": 875
    },
    {
      "epoch": 0.17146123071061153,
      "grad_norm": 1.284083366394043,
      "learning_rate": 0.0009458495253870167,
      "loss": 0.2857,
      "step": 900
    },
    {
      "epoch": 0.1762240426747952,
      "grad_norm": 0.5948335528373718,
      "learning_rate": 0.0009442568643689877,
      "loss": 0.2727,
      "step": 925
    },
    {
      "epoch": 0.18098685463897884,
      "grad_norm": 0.5735719203948975,
      "learning_rate": 0.0009426642033509589,
      "loss": 0.2597,
      "step": 950
    },
    {
      "epoch": 0.1857496666031625,
      "grad_norm": 1.0884729623794556,
      "learning_rate": 0.0009410715423329299,
      "loss": 0.3022,
      "step": 975
    },
    {
      "epoch": 0.19051247856734616,
      "grad_norm": 1.4780000448226929,
      "learning_rate": 0.0009395425877556221,
      "loss": 0.3161,
      "step": 1000
    },
    {
      "epoch": 0.1952752905315298,
      "grad_norm": 0.7770857810974121,
      "learning_rate": 0.0009379499267375931,
      "loss": 0.2611,
      "step": 1025
    },
    {
      "epoch": 0.20003810249571347,
      "grad_norm": 0.6237686276435852,
      "learning_rate": 0.0009363572657195643,
      "loss": 0.269,
      "step": 1050
    },
    {
      "epoch": 0.20480091445989712,
      "grad_norm": 0.7096232771873474,
      "learning_rate": 0.0009347646047015353,
      "loss": 0.2968,
      "step": 1075
    },
    {
      "epoch": 0.20956372642408078,
      "grad_norm": 0.382939875125885,
      "learning_rate": 0.0009331719436835064,
      "loss": 0.2652,
      "step": 1100
    },
    {
      "epoch": 0.21432653838826443,
      "grad_norm": 0.5680379867553711,
      "learning_rate": 0.0009315792826654775,
      "loss": 0.2683,
      "step": 1125
    },
    {
      "epoch": 0.2190893503524481,
      "grad_norm": 0.6426520347595215,
      "learning_rate": 0.0009299866216474486,
      "loss": 0.2697,
      "step": 1150
    },
    {
      "epoch": 0.22385216231663174,
      "grad_norm": 0.6635845899581909,
      "learning_rate": 0.0009283939606294196,
      "loss": 0.2576,
      "step": 1175
    },
    {
      "epoch": 0.2286149742808154,
      "grad_norm": 0.4672934114933014,
      "learning_rate": 0.0009268012996113907,
      "loss": 0.2491,
      "step": 1200
    },
    {
      "epoch": 0.23337778624499905,
      "grad_norm": 0.6626129746437073,
      "learning_rate": 0.0009252086385933618,
      "loss": 0.2493,
      "step": 1225
    },
    {
      "epoch": 0.2381405982091827,
      "grad_norm": 0.592166006565094,
      "learning_rate": 0.0009236159775753329,
      "loss": 0.2555,
      "step": 1250
    },
    {
      "epoch": 0.24290341017336636,
      "grad_norm": 0.6160594820976257,
      "learning_rate": 0.000922023316557304,
      "loss": 0.2522,
      "step": 1275
    },
    {
      "epoch": 0.24766622213755002,
      "grad_norm": 0.4531233310699463,
      "learning_rate": 0.0009204306555392751,
      "loss": 0.2341,
      "step": 1300
    },
    {
      "epoch": 0.2524290341017337,
      "grad_norm": 0.5025535821914673,
      "learning_rate": 0.0009188379945212462,
      "loss": 0.2526,
      "step": 1325
    },
    {
      "epoch": 0.25719184606591733,
      "grad_norm": 1.0313199758529663,
      "learning_rate": 0.0009172453335032171,
      "loss": 0.2483,
      "step": 1350
    },
    {
      "epoch": 0.261954658030101,
      "grad_norm": 0.582768976688385,
      "learning_rate": 0.0009156526724851883,
      "loss": 0.2272,
      "step": 1375
    },
    {
      "epoch": 0.26671746999428464,
      "grad_norm": 0.5592681765556335,
      "learning_rate": 0.0009140600114671593,
      "loss": 0.2578,
      "step": 1400
    },
    {
      "epoch": 0.2714802819584683,
      "grad_norm": 0.6581587791442871,
      "learning_rate": 0.0009124673504491305,
      "loss": 0.2641,
      "step": 1425
    },
    {
      "epoch": 0.27624309392265195,
      "grad_norm": 1.0348138809204102,
      "learning_rate": 0.0009108746894311015,
      "loss": 0.2589,
      "step": 1450
    },
    {
      "epoch": 0.2810059058868356,
      "grad_norm": 0.7861711382865906,
      "learning_rate": 0.0009092820284130726,
      "loss": 0.2326,
      "step": 1475
    },
    {
      "epoch": 0.28576871785101926,
      "grad_norm": 0.5201400518417358,
      "learning_rate": 0.0009076893673950437,
      "loss": 0.2575,
      "step": 1500
    },
    {
      "epoch": 0.2905315298152029,
      "grad_norm": 0.6072205305099487,
      "learning_rate": 0.0009060967063770147,
      "loss": 0.2512,
      "step": 1525
    },
    {
      "epoch": 0.29529434177938657,
      "grad_norm": 0.5886487364768982,
      "learning_rate": 0.0009045040453589858,
      "loss": 0.2398,
      "step": 1550
    },
    {
      "epoch": 0.3000571537435702,
      "grad_norm": 0.8002530932426453,
      "learning_rate": 0.0009029113843409569,
      "loss": 0.2661,
      "step": 1575
    },
    {
      "epoch": 0.3048199657077539,
      "grad_norm": 0.5999667644500732,
      "learning_rate": 0.0009013187233229279,
      "loss": 0.2356,
      "step": 1600
    },
    {
      "epoch": 0.30958277767193754,
      "grad_norm": 1.0486819744110107,
      "learning_rate": 0.0008997260623048991,
      "loss": 0.2427,
      "step": 1625
    },
    {
      "epoch": 0.3143455896361212,
      "grad_norm": 0.4335174858570099,
      "learning_rate": 0.0008981334012868701,
      "loss": 0.2591,
      "step": 1650
    },
    {
      "epoch": 0.31910840160030485,
      "grad_norm": 0.4837844669818878,
      "learning_rate": 0.0008965407402688413,
      "loss": 0.2523,
      "step": 1675
    },
    {
      "epoch": 0.32387121356448845,
      "grad_norm": 0.4954235851764679,
      "learning_rate": 0.0008949480792508122,
      "loss": 0.2267,
      "step": 1700
    },
    {
      "epoch": 0.3286340255286721,
      "grad_norm": 0.7508940696716309,
      "learning_rate": 0.0008933554182327833,
      "loss": 0.2391,
      "step": 1725
    },
    {
      "epoch": 0.33339683749285576,
      "grad_norm": 0.4688863456249237,
      "learning_rate": 0.0008917627572147544,
      "loss": 0.2198,
      "step": 1750
    },
    {
      "epoch": 0.3381596494570394,
      "grad_norm": 0.5708208680152893,
      "learning_rate": 0.0008901700961967255,
      "loss": 0.2566,
      "step": 1775
    },
    {
      "epoch": 0.34292246142122307,
      "grad_norm": 0.5533339977264404,
      "learning_rate": 0.0008885774351786966,
      "loss": 0.2464,
      "step": 1800
    },
    {
      "epoch": 0.3476852733854067,
      "grad_norm": 0.5541612505912781,
      "learning_rate": 0.0008869847741606677,
      "loss": 0.2595,
      "step": 1825
    },
    {
      "epoch": 0.3524480853495904,
      "grad_norm": 0.42225366830825806,
      "learning_rate": 0.0008853921131426387,
      "loss": 0.234,
      "step": 1850
    },
    {
      "epoch": 0.35721089731377403,
      "grad_norm": 0.6770257949829102,
      "learning_rate": 0.0008837994521246098,
      "loss": 0.23,
      "step": 1875
    },
    {
      "epoch": 0.3619737092779577,
      "grad_norm": 0.5134340524673462,
      "learning_rate": 0.0008822067911065808,
      "loss": 0.2368,
      "step": 1900
    },
    {
      "epoch": 0.36673652124214134,
      "grad_norm": 0.5036235451698303,
      "learning_rate": 0.000880614130088552,
      "loss": 0.2353,
      "step": 1925
    },
    {
      "epoch": 0.371499333206325,
      "grad_norm": 0.5326038599014282,
      "learning_rate": 0.000879021469070523,
      "loss": 0.218,
      "step": 1950
    },
    {
      "epoch": 0.37626214517050866,
      "grad_norm": 0.4621608555316925,
      "learning_rate": 0.0008774288080524941,
      "loss": 0.2399,
      "step": 1975
    },
    {
      "epoch": 0.3810249571346923,
      "grad_norm": 0.8987313508987427,
      "learning_rate": 0.0008758361470344653,
      "loss": 0.233,
      "step": 2000
    },
    {
      "epoch": 0.38578776909887597,
      "grad_norm": 0.5364629030227661,
      "learning_rate": 0.0008742434860164363,
      "loss": 0.2388,
      "step": 2025
    },
    {
      "epoch": 0.3905505810630596,
      "grad_norm": 0.7487062811851501,
      "learning_rate": 0.0008726508249984074,
      "loss": 0.2372,
      "step": 2050
    },
    {
      "epoch": 0.3953133930272433,
      "grad_norm": 0.5832078456878662,
      "learning_rate": 0.0008710581639803784,
      "loss": 0.2425,
      "step": 2075
    },
    {
      "epoch": 0.40007620499142693,
      "grad_norm": 0.5074911117553711,
      "learning_rate": 0.0008694655029623495,
      "loss": 0.2336,
      "step": 2100
    },
    {
      "epoch": 0.4048390169556106,
      "grad_norm": 0.7011171579360962,
      "learning_rate": 0.0008678728419443206,
      "loss": 0.2424,
      "step": 2125
    },
    {
      "epoch": 0.40960182891979424,
      "grad_norm": 0.4492656886577606,
      "learning_rate": 0.0008662801809262917,
      "loss": 0.2194,
      "step": 2150
    },
    {
      "epoch": 0.4143646408839779,
      "grad_norm": 0.7280007600784302,
      "learning_rate": 0.0008646875199082628,
      "loss": 0.2463,
      "step": 2175
    },
    {
      "epoch": 0.41912745284816155,
      "grad_norm": 0.6941392421722412,
      "learning_rate": 0.0008630948588902339,
      "loss": 0.2243,
      "step": 2200
    },
    {
      "epoch": 0.4238902648123452,
      "grad_norm": 0.40749508142471313,
      "learning_rate": 0.0008615021978722048,
      "loss": 0.2126,
      "step": 2225
    },
    {
      "epoch": 0.42865307677652886,
      "grad_norm": 0.4562365412712097,
      "learning_rate": 0.000859909536854176,
      "loss": 0.2125,
      "step": 2250
    },
    {
      "epoch": 0.4334158887407125,
      "grad_norm": 1.1745280027389526,
      "learning_rate": 0.000858316875836147,
      "loss": 0.2423,
      "step": 2275
    },
    {
      "epoch": 0.4381787007048962,
      "grad_norm": 0.589699923992157,
      "learning_rate": 0.0008567242148181182,
      "loss": 0.2206,
      "step": 2300
    },
    {
      "epoch": 0.44294151266907983,
      "grad_norm": 0.45881929993629456,
      "learning_rate": 0.0008551315538000892,
      "loss": 0.2174,
      "step": 2325
    },
    {
      "epoch": 0.4477043246332635,
      "grad_norm": 0.5662843585014343,
      "learning_rate": 0.0008535388927820603,
      "loss": 0.2219,
      "step": 2350
    },
    {
      "epoch": 0.45246713659744714,
      "grad_norm": 0.6486897468566895,
      "learning_rate": 0.0008519462317640314,
      "loss": 0.2162,
      "step": 2375
    },
    {
      "epoch": 0.4572299485616308,
      "grad_norm": 0.3361331522464752,
      "learning_rate": 0.0008503535707460024,
      "loss": 0.2251,
      "step": 2400
    },
    {
      "epoch": 0.46199276052581445,
      "grad_norm": 0.4630430042743683,
      "learning_rate": 0.0008487609097279735,
      "loss": 0.2409,
      "step": 2425
    },
    {
      "epoch": 0.4667555724899981,
      "grad_norm": 0.5586747527122498,
      "learning_rate": 0.0008471682487099446,
      "loss": 0.2292,
      "step": 2450
    },
    {
      "epoch": 0.47151838445418176,
      "grad_norm": 0.5390704274177551,
      "learning_rate": 0.0008455755876919156,
      "loss": 0.237,
      "step": 2475
    },
    {
      "epoch": 0.4762811964183654,
      "grad_norm": 0.7055178880691528,
      "learning_rate": 0.0008439829266738868,
      "loss": 0.2322,
      "step": 2500
    },
    {
      "epoch": 0.48104400838254907,
      "grad_norm": 0.47772833704948425,
      "learning_rate": 0.0008423902656558578,
      "loss": 0.2155,
      "step": 2525
    },
    {
      "epoch": 0.4858068203467327,
      "grad_norm": 0.6652612686157227,
      "learning_rate": 0.000840797604637829,
      "loss": 0.2171,
      "step": 2550
    },
    {
      "epoch": 0.4905696323109164,
      "grad_norm": 0.4368745684623718,
      "learning_rate": 0.0008392049436197999,
      "loss": 0.2385,
      "step": 2575
    },
    {
      "epoch": 0.49533244427510004,
      "grad_norm": 0.7170118093490601,
      "learning_rate": 0.000837612282601771,
      "loss": 0.2204,
      "step": 2600
    },
    {
      "epoch": 0.5000952562392836,
      "grad_norm": 0.36290717124938965,
      "learning_rate": 0.0008360196215837421,
      "loss": 0.2072,
      "step": 2625
    },
    {
      "epoch": 0.5048580682034673,
      "grad_norm": 0.5072658658027649,
      "learning_rate": 0.0008344269605657132,
      "loss": 0.2102,
      "step": 2650
    },
    {
      "epoch": 0.509620880167651,
      "grad_norm": 0.49327462911605835,
      "learning_rate": 0.0008328342995476843,
      "loss": 0.2242,
      "step": 2675
    },
    {
      "epoch": 0.5143836921318347,
      "grad_norm": 0.3459867537021637,
      "learning_rate": 0.0008312416385296554,
      "loss": 0.2019,
      "step": 2700
    },
    {
      "epoch": 0.5191465040960183,
      "grad_norm": 0.4783022999763489,
      "learning_rate": 0.0008296489775116265,
      "loss": 0.199,
      "step": 2725
    },
    {
      "epoch": 0.523909316060202,
      "grad_norm": 0.570830225944519,
      "learning_rate": 0.0008280563164935975,
      "loss": 0.2072,
      "step": 2750
    },
    {
      "epoch": 0.5286721280243856,
      "grad_norm": 0.4868229925632477,
      "learning_rate": 0.0008264636554755686,
      "loss": 0.2296,
      "step": 2775
    },
    {
      "epoch": 0.5334349399885693,
      "grad_norm": 0.619123637676239,
      "learning_rate": 0.0008248709944575397,
      "loss": 0.2144,
      "step": 2800
    },
    {
      "epoch": 0.5381977519527529,
      "grad_norm": 0.6282219290733337,
      "learning_rate": 0.0008232783334395108,
      "loss": 0.2268,
      "step": 2825
    },
    {
      "epoch": 0.5429605639169366,
      "grad_norm": 0.5833483934402466,
      "learning_rate": 0.0008216856724214818,
      "loss": 0.2191,
      "step": 2850
    },
    {
      "epoch": 0.5477233758811202,
      "grad_norm": 0.5944212675094604,
      "learning_rate": 0.000820093011403453,
      "loss": 0.2133,
      "step": 2875
    },
    {
      "epoch": 0.5524861878453039,
      "grad_norm": 0.5155736804008484,
      "learning_rate": 0.000818500350385424,
      "loss": 0.2118,
      "step": 2900
    },
    {
      "epoch": 0.5572489998094875,
      "grad_norm": 0.5530818104743958,
      "learning_rate": 0.000816907689367395,
      "loss": 0.2372,
      "step": 2925
    },
    {
      "epoch": 0.5620118117736712,
      "grad_norm": 0.5287671685218811,
      "learning_rate": 0.0008153150283493661,
      "loss": 0.2104,
      "step": 2950
    },
    {
      "epoch": 0.5667746237378548,
      "grad_norm": 0.3293258547782898,
      "learning_rate": 0.0008137223673313372,
      "loss": 0.2125,
      "step": 2975
    },
    {
      "epoch": 0.5715374357020385,
      "grad_norm": 0.41668596863746643,
      "learning_rate": 0.0008121297063133083,
      "loss": 0.2134,
      "step": 3000
    },
    {
      "epoch": 0.5763002476662221,
      "grad_norm": 0.5170421004295349,
      "learning_rate": 0.0008105370452952794,
      "loss": 0.2044,
      "step": 3025
    },
    {
      "epoch": 0.5810630596304058,
      "grad_norm": 0.3759912848472595,
      "learning_rate": 0.0008089443842772505,
      "loss": 0.2133,
      "step": 3050
    },
    {
      "epoch": 0.5858258715945894,
      "grad_norm": 0.44944822788238525,
      "learning_rate": 0.0008073517232592216,
      "loss": 0.2343,
      "step": 3075
    },
    {
      "epoch": 0.5905886835587731,
      "grad_norm": 0.644844651222229,
      "learning_rate": 0.0008057590622411925,
      "loss": 0.2114,
      "step": 3100
    },
    {
      "epoch": 0.5953514955229567,
      "grad_norm": 0.4761384427547455,
      "learning_rate": 0.0008041664012231637,
      "loss": 0.1977,
      "step": 3125
    },
    {
      "epoch": 0.6001143074871405,
      "grad_norm": 0.5005059242248535,
      "learning_rate": 0.0008025737402051347,
      "loss": 0.2245,
      "step": 3150
    },
    {
      "epoch": 0.604877119451324,
      "grad_norm": 0.5414678454399109,
      "learning_rate": 0.0008009810791871059,
      "loss": 0.2163,
      "step": 3175
    },
    {
      "epoch": 0.6096399314155078,
      "grad_norm": 0.5178296566009521,
      "learning_rate": 0.0007993884181690769,
      "loss": 0.2319,
      "step": 3200
    },
    {
      "epoch": 0.6144027433796914,
      "grad_norm": 0.7426254749298096,
      "learning_rate": 0.000797795757151048,
      "loss": 0.2107,
      "step": 3225
    },
    {
      "epoch": 0.6191655553438751,
      "grad_norm": 0.6089995503425598,
      "learning_rate": 0.0007962030961330191,
      "loss": 0.222,
      "step": 3250
    },
    {
      "epoch": 0.6239283673080587,
      "grad_norm": 0.4871472120285034,
      "learning_rate": 0.0007946104351149901,
      "loss": 0.2049,
      "step": 3275
    },
    {
      "epoch": 0.6286911792722424,
      "grad_norm": 0.8270655870437622,
      "learning_rate": 0.0007930177740969611,
      "loss": 0.2174,
      "step": 3300
    },
    {
      "epoch": 0.633453991236426,
      "grad_norm": 0.45445841550827026,
      "learning_rate": 0.0007914251130789323,
      "loss": 0.2155,
      "step": 3325
    },
    {
      "epoch": 0.6382168032006097,
      "grad_norm": 0.53960782289505,
      "learning_rate": 0.0007898324520609033,
      "loss": 0.2147,
      "step": 3350
    },
    {
      "epoch": 0.6429796151647933,
      "grad_norm": 0.6571884751319885,
      "learning_rate": 0.0007882397910428745,
      "loss": 0.1989,
      "step": 3375
    },
    {
      "epoch": 0.6477424271289769,
      "grad_norm": 0.579545259475708,
      "learning_rate": 0.0007866471300248455,
      "loss": 0.2276,
      "step": 3400
    },
    {
      "epoch": 0.6525052390931606,
      "grad_norm": 0.5038416981697083,
      "learning_rate": 0.0007850544690068167,
      "loss": 0.2262,
      "step": 3425
    },
    {
      "epoch": 0.6572680510573442,
      "grad_norm": 0.6479758620262146,
      "learning_rate": 0.0007834618079887876,
      "loss": 0.2175,
      "step": 3450
    },
    {
      "epoch": 0.6620308630215279,
      "grad_norm": 0.3650793433189392,
      "learning_rate": 0.0007818691469707587,
      "loss": 0.2217,
      "step": 3475
    },
    {
      "epoch": 0.6667936749857115,
      "grad_norm": 0.5178789496421814,
      "learning_rate": 0.0007802764859527299,
      "loss": 0.2187,
      "step": 3500
    },
    {
      "epoch": 0.6715564869498952,
      "grad_norm": 0.47134891152381897,
      "learning_rate": 0.0007786838249347009,
      "loss": 0.1925,
      "step": 3525
    },
    {
      "epoch": 0.6763192989140788,
      "grad_norm": 0.48790931701660156,
      "learning_rate": 0.0007770911639166721,
      "loss": 0.233,
      "step": 3550
    },
    {
      "epoch": 0.6810821108782625,
      "grad_norm": 0.4760911464691162,
      "learning_rate": 0.0007754985028986431,
      "loss": 0.2053,
      "step": 3575
    },
    {
      "epoch": 0.6858449228424461,
      "grad_norm": 0.39133307337760925,
      "learning_rate": 0.0007739058418806142,
      "loss": 0.2201,
      "step": 3600
    },
    {
      "epoch": 0.6906077348066298,
      "grad_norm": 0.38274091482162476,
      "learning_rate": 0.0007723131808625852,
      "loss": 0.197,
      "step": 3625
    },
    {
      "epoch": 0.6953705467708134,
      "grad_norm": 0.5759918689727783,
      "learning_rate": 0.0007707205198445563,
      "loss": 0.2092,
      "step": 3650
    },
    {
      "epoch": 0.7001333587349972,
      "grad_norm": 0.9064395427703857,
      "learning_rate": 0.0007691278588265273,
      "loss": 0.2115,
      "step": 3675
    },
    {
      "epoch": 0.7048961706991808,
      "grad_norm": 0.5737283825874329,
      "learning_rate": 0.0007675351978084985,
      "loss": 0.205,
      "step": 3700
    },
    {
      "epoch": 0.7096589826633645,
      "grad_norm": 0.6317829489707947,
      "learning_rate": 0.0007659425367904695,
      "loss": 0.2107,
      "step": 3725
    },
    {
      "epoch": 0.7144217946275481,
      "grad_norm": 0.6658796668052673,
      "learning_rate": 0.0007643498757724407,
      "loss": 0.2115,
      "step": 3750
    },
    {
      "epoch": 0.7191846065917318,
      "grad_norm": 0.512086033821106,
      "learning_rate": 0.0007627572147544117,
      "loss": 0.219,
      "step": 3775
    },
    {
      "epoch": 0.7239474185559154,
      "grad_norm": 0.3275403082370758,
      "learning_rate": 0.0007611645537363827,
      "loss": 0.1938,
      "step": 3800
    },
    {
      "epoch": 0.7287102305200991,
      "grad_norm": 0.528786838054657,
      "learning_rate": 0.0007595718927183538,
      "loss": 0.1893,
      "step": 3825
    },
    {
      "epoch": 0.7334730424842827,
      "grad_norm": 0.3800594210624695,
      "learning_rate": 0.0007579792317003249,
      "loss": 0.1888,
      "step": 3850
    },
    {
      "epoch": 0.7382358544484664,
      "grad_norm": 0.42430710792541504,
      "learning_rate": 0.000756386570682296,
      "loss": 0.1906,
      "step": 3875
    },
    {
      "epoch": 0.74299866641265,
      "grad_norm": 0.49497488141059875,
      "learning_rate": 0.0007547939096642671,
      "loss": 0.2033,
      "step": 3900
    },
    {
      "epoch": 0.7477614783768337,
      "grad_norm": 1.3972939252853394,
      "learning_rate": 0.0007532012486462381,
      "loss": 0.2061,
      "step": 3925
    },
    {
      "epoch": 0.7525242903410173,
      "grad_norm": 0.381188303232193,
      "learning_rate": 0.0007516085876282093,
      "loss": 0.1856,
      "step": 3950
    },
    {
      "epoch": 0.757287102305201,
      "grad_norm": 0.4281092584133148,
      "learning_rate": 0.0007500159266101802,
      "loss": 0.199,
      "step": 3975
    },
    {
      "epoch": 0.7620499142693846,
      "grad_norm": 0.4876241683959961,
      "learning_rate": 0.0007484232655921514,
      "loss": 0.222,
      "step": 4000
    },
    {
      "epoch": 0.7668127262335683,
      "grad_norm": 0.416217178106308,
      "learning_rate": 0.0007468306045741224,
      "loss": 0.2033,
      "step": 4025
    },
    {
      "epoch": 0.7715755381977519,
      "grad_norm": 0.49797090888023376,
      "learning_rate": 0.0007452379435560935,
      "loss": 0.21,
      "step": 4050
    },
    {
      "epoch": 0.7763383501619356,
      "grad_norm": 0.522446870803833,
      "learning_rate": 0.0007436452825380646,
      "loss": 0.1815,
      "step": 4075
    },
    {
      "epoch": 0.7811011621261192,
      "grad_norm": 0.49915432929992676,
      "learning_rate": 0.0007420526215200357,
      "loss": 0.2047,
      "step": 4100
    },
    {
      "epoch": 0.785863974090303,
      "grad_norm": 0.3782380223274231,
      "learning_rate": 0.0007404599605020068,
      "loss": 0.2076,
      "step": 4125
    },
    {
      "epoch": 0.7906267860544866,
      "grad_norm": 0.3725324273109436,
      "learning_rate": 0.0007388672994839778,
      "loss": 0.2071,
      "step": 4150
    },
    {
      "epoch": 0.7953895980186703,
      "grad_norm": 0.4311428666114807,
      "learning_rate": 0.0007372746384659488,
      "loss": 0.2053,
      "step": 4175
    },
    {
      "epoch": 0.8001524099828539,
      "grad_norm": 0.7100840210914612,
      "learning_rate": 0.00073568197744792,
      "loss": 0.193,
      "step": 4200
    },
    {
      "epoch": 0.8049152219470376,
      "grad_norm": 0.3658846318721771,
      "learning_rate": 0.000734089316429891,
      "loss": 0.2042,
      "step": 4225
    },
    {
      "epoch": 0.8096780339112212,
      "grad_norm": 0.27370914816856384,
      "learning_rate": 0.0007324966554118622,
      "loss": 0.2006,
      "step": 4250
    },
    {
      "epoch": 0.8144408458754049,
      "grad_norm": 0.40199559926986694,
      "learning_rate": 0.0007309039943938333,
      "loss": 0.1982,
      "step": 4275
    },
    {
      "epoch": 0.8192036578395885,
      "grad_norm": 0.5410312414169312,
      "learning_rate": 0.0007293113333758043,
      "loss": 0.2169,
      "step": 4300
    },
    {
      "epoch": 0.8239664698037722,
      "grad_norm": 0.6718910336494446,
      "learning_rate": 0.0007277186723577754,
      "loss": 0.2185,
      "step": 4325
    },
    {
      "epoch": 0.8287292817679558,
      "grad_norm": 0.701155960559845,
      "learning_rate": 0.0007261260113397464,
      "loss": 0.2058,
      "step": 4350
    },
    {
      "epoch": 0.8334920937321395,
      "grad_norm": 0.49956464767456055,
      "learning_rate": 0.0007245333503217176,
      "loss": 0.2023,
      "step": 4375
    },
    {
      "epoch": 0.8382549056963231,
      "grad_norm": 0.4587194323539734,
      "learning_rate": 0.0007229406893036886,
      "loss": 0.1819,
      "step": 4400
    },
    {
      "epoch": 0.8430177176605068,
      "grad_norm": 0.5795965194702148,
      "learning_rate": 0.0007213480282856597,
      "loss": 0.2144,
      "step": 4425
    },
    {
      "epoch": 0.8477805296246904,
      "grad_norm": 0.5199795365333557,
      "learning_rate": 0.0007197553672676308,
      "loss": 0.1979,
      "step": 4450
    },
    {
      "epoch": 0.8525433415888741,
      "grad_norm": 0.4996715486049652,
      "learning_rate": 0.0007181627062496019,
      "loss": 0.2078,
      "step": 4475
    },
    {
      "epoch": 0.8573061535530577,
      "grad_norm": 0.5281824469566345,
      "learning_rate": 0.0007165700452315729,
      "loss": 0.1921,
      "step": 4500
    },
    {
      "epoch": 0.8620689655172413,
      "grad_norm": 0.5007298588752747,
      "learning_rate": 0.000714977384213544,
      "loss": 0.2011,
      "step": 4525
    },
    {
      "epoch": 0.866831777481425,
      "grad_norm": 0.30167296528816223,
      "learning_rate": 0.000713384723195515,
      "loss": 0.1768,
      "step": 4550
    },
    {
      "epoch": 0.8715945894456086,
      "grad_norm": 0.7112186551094055,
      "learning_rate": 0.0007117920621774862,
      "loss": 0.2213,
      "step": 4575
    },
    {
      "epoch": 0.8763574014097923,
      "grad_norm": 0.40796324610710144,
      "learning_rate": 0.0007101994011594572,
      "loss": 0.2335,
      "step": 4600
    },
    {
      "epoch": 0.881120213373976,
      "grad_norm": 0.7855066061019897,
      "learning_rate": 0.0007086067401414284,
      "loss": 0.2235,
      "step": 4625
    },
    {
      "epoch": 0.8858830253381597,
      "grad_norm": 0.41058114171028137,
      "learning_rate": 0.0007070140791233994,
      "loss": 0.2023,
      "step": 4650
    },
    {
      "epoch": 0.8906458373023433,
      "grad_norm": 0.6187407374382019,
      "learning_rate": 0.0007054214181053704,
      "loss": 0.2144,
      "step": 4675
    },
    {
      "epoch": 0.895408649266527,
      "grad_norm": 0.988623321056366,
      "learning_rate": 0.0007038287570873415,
      "loss": 0.1885,
      "step": 4700
    },
    {
      "epoch": 0.9001714612307106,
      "grad_norm": 0.4264851212501526,
      "learning_rate": 0.0007022360960693126,
      "loss": 0.2007,
      "step": 4725
    },
    {
      "epoch": 0.9049342731948943,
      "grad_norm": 0.5118142366409302,
      "learning_rate": 0.0007006434350512837,
      "loss": 0.1935,
      "step": 4750
    },
    {
      "epoch": 0.9096970851590779,
      "grad_norm": 0.36253756284713745,
      "learning_rate": 0.0006990507740332548,
      "loss": 0.1937,
      "step": 4775
    },
    {
      "epoch": 0.9144598971232616,
      "grad_norm": 0.5168668627738953,
      "learning_rate": 0.0006974581130152258,
      "loss": 0.2047,
      "step": 4800
    },
    {
      "epoch": 0.9192227090874452,
      "grad_norm": 0.5096656084060669,
      "learning_rate": 0.000695865451997197,
      "loss": 0.2051,
      "step": 4825
    },
    {
      "epoch": 0.9239855210516289,
      "grad_norm": 0.46031761169433594,
      "learning_rate": 0.0006942727909791679,
      "loss": 0.1975,
      "step": 4850
    },
    {
      "epoch": 0.9287483330158125,
      "grad_norm": 0.4420437216758728,
      "learning_rate": 0.0006926801299611391,
      "loss": 0.1735,
      "step": 4875
    },
    {
      "epoch": 0.9335111449799962,
      "grad_norm": 0.42825356125831604,
      "learning_rate": 0.0006910874689431101,
      "loss": 0.1908,
      "step": 4900
    },
    {
      "epoch": 0.9382739569441798,
      "grad_norm": 0.3995630741119385,
      "learning_rate": 0.0006894948079250812,
      "loss": 0.1992,
      "step": 4925
    },
    {
      "epoch": 0.9430367689083635,
      "grad_norm": 0.5905767679214478,
      "learning_rate": 0.0006879021469070523,
      "loss": 0.1846,
      "step": 4950
    },
    {
      "epoch": 0.9477995808725471,
      "grad_norm": 0.6631248593330383,
      "learning_rate": 0.0006863094858890234,
      "loss": 0.1898,
      "step": 4975
    },
    {
      "epoch": 0.9525623928367308,
      "grad_norm": 0.5423727035522461,
      "learning_rate": 0.0006847168248709945,
      "loss": 0.1771,
      "step": 5000
    },
    {
      "epoch": 0.9573252048009144,
      "grad_norm": 0.3690667152404785,
      "learning_rate": 0.0006831241638529655,
      "loss": 0.205,
      "step": 5025
    },
    {
      "epoch": 0.9620880167650981,
      "grad_norm": 0.5986637473106384,
      "learning_rate": 0.0006815315028349366,
      "loss": 0.1835,
      "step": 5050
    },
    {
      "epoch": 0.9668508287292817,
      "grad_norm": 0.40431350469589233,
      "learning_rate": 0.0006799388418169077,
      "loss": 0.1901,
      "step": 5075
    },
    {
      "epoch": 0.9716136406934655,
      "grad_norm": 0.4352132976055145,
      "learning_rate": 0.0006783461807988788,
      "loss": 0.1976,
      "step": 5100
    },
    {
      "epoch": 0.976376452657649,
      "grad_norm": 0.3673841953277588,
      "learning_rate": 0.0006767535197808499,
      "loss": 0.1883,
      "step": 5125
    },
    {
      "epoch": 0.9811392646218328,
      "grad_norm": 0.39037421345710754,
      "learning_rate": 0.000675160858762821,
      "loss": 0.192,
      "step": 5150
    },
    {
      "epoch": 0.9859020765860164,
      "grad_norm": 0.7837408185005188,
      "learning_rate": 0.000673568197744792,
      "loss": 0.1821,
      "step": 5175
    },
    {
      "epoch": 0.9906648885502001,
      "grad_norm": 0.47465160489082336,
      "learning_rate": 0.0006719755367267631,
      "loss": 0.1919,
      "step": 5200
    },
    {
      "epoch": 0.9954277005143837,
      "grad_norm": 0.7830988764762878,
      "learning_rate": 0.0006703828757087341,
      "loss": 0.1814,
      "step": 5225
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.19503019750118256,
      "eval_runtime": 3792.0475,
      "eval_samples_per_second": 5.273,
      "eval_steps_per_second": 0.659,
      "step": 5249
    },
    {
      "epoch": 1.0001905124785673,
      "grad_norm": 0.38589760661125183,
      "learning_rate": 0.0006687902146907053,
      "loss": 0.1887,
      "step": 5250
    },
    {
      "epoch": 1.004953324442751,
      "grad_norm": 0.6158744096755981,
      "learning_rate": 0.0006671975536726763,
      "loss": 0.1557,
      "step": 5275
    },
    {
      "epoch": 1.0097161364069347,
      "grad_norm": 0.38704952597618103,
      "learning_rate": 0.0006656048926546474,
      "loss": 0.1707,
      "step": 5300
    },
    {
      "epoch": 1.0144789483711183,
      "grad_norm": 0.3795446455478668,
      "learning_rate": 0.0006640122316366185,
      "loss": 0.1602,
      "step": 5325
    },
    {
      "epoch": 1.019241760335302,
      "grad_norm": 0.45102694630622864,
      "learning_rate": 0.0006624195706185896,
      "loss": 0.1872,
      "step": 5350
    },
    {
      "epoch": 1.0240045722994857,
      "grad_norm": 0.6246707439422607,
      "learning_rate": 0.0006608269096005606,
      "loss": 0.1555,
      "step": 5375
    },
    {
      "epoch": 1.0287673842636693,
      "grad_norm": 0.4400193989276886,
      "learning_rate": 0.0006592342485825317,
      "loss": 0.1785,
      "step": 5400
    },
    {
      "epoch": 1.033530196227853,
      "grad_norm": 0.46513238549232483,
      "learning_rate": 0.0006576415875645027,
      "loss": 0.1751,
      "step": 5425
    },
    {
      "epoch": 1.0382930081920365,
      "grad_norm": 0.51124507188797,
      "learning_rate": 0.0006560489265464739,
      "loss": 0.1658,
      "step": 5450
    },
    {
      "epoch": 1.0430558201562203,
      "grad_norm": 0.4376438856124878,
      "learning_rate": 0.0006544562655284449,
      "loss": 0.1727,
      "step": 5475
    },
    {
      "epoch": 1.047818632120404,
      "grad_norm": 0.42765331268310547,
      "learning_rate": 0.0006528636045104161,
      "loss": 0.1636,
      "step": 5500
    },
    {
      "epoch": 1.0525814440845875,
      "grad_norm": 0.6815279722213745,
      "learning_rate": 0.0006512709434923871,
      "loss": 0.1561,
      "step": 5525
    },
    {
      "epoch": 1.0573442560487711,
      "grad_norm": 0.4205758571624756,
      "learning_rate": 0.0006496782824743581,
      "loss": 0.1513,
      "step": 5550
    },
    {
      "epoch": 1.062107068012955,
      "grad_norm": 0.6202410459518433,
      "learning_rate": 0.0006480856214563292,
      "loss": 0.1925,
      "step": 5575
    },
    {
      "epoch": 1.0668698799771386,
      "grad_norm": 0.3148711025714874,
      "learning_rate": 0.0006464929604383003,
      "loss": 0.174,
      "step": 5600
    },
    {
      "epoch": 1.0716326919413222,
      "grad_norm": 0.405016154050827,
      "learning_rate": 0.0006449002994202714,
      "loss": 0.1699,
      "step": 5625
    },
    {
      "epoch": 1.0763955039055058,
      "grad_norm": 0.4009762704372406,
      "learning_rate": 0.0006433076384022425,
      "loss": 0.1807,
      "step": 5650
    },
    {
      "epoch": 1.0811583158696894,
      "grad_norm": 0.5345812439918518,
      "learning_rate": 0.0006417149773842135,
      "loss": 0.161,
      "step": 5675
    },
    {
      "epoch": 1.0859211278338732,
      "grad_norm": 0.4936438500881195,
      "learning_rate": 0.0006401223163661847,
      "loss": 0.1834,
      "step": 5700
    },
    {
      "epoch": 1.0906839397980568,
      "grad_norm": 0.4004095792770386,
      "learning_rate": 0.0006385296553481556,
      "loss": 0.1785,
      "step": 5725
    },
    {
      "epoch": 1.0954467517622404,
      "grad_norm": 0.28582558035850525,
      "learning_rate": 0.0006369369943301268,
      "loss": 0.1619,
      "step": 5750
    },
    {
      "epoch": 1.100209563726424,
      "grad_norm": 0.45266780257225037,
      "learning_rate": 0.0006353443333120978,
      "loss": 0.1723,
      "step": 5775
    },
    {
      "epoch": 1.1049723756906078,
      "grad_norm": 0.4222641587257385,
      "learning_rate": 0.0006337516722940689,
      "loss": 0.1627,
      "step": 5800
    },
    {
      "epoch": 1.1097351876547914,
      "grad_norm": 0.2539794445037842,
      "learning_rate": 0.0006321590112760401,
      "loss": 0.1703,
      "step": 5825
    },
    {
      "epoch": 1.114497999618975,
      "grad_norm": 0.3339717388153076,
      "learning_rate": 0.0006305663502580111,
      "loss": 0.1697,
      "step": 5850
    },
    {
      "epoch": 1.1192608115831586,
      "grad_norm": 0.4399562478065491,
      "learning_rate": 0.0006289736892399823,
      "loss": 0.1615,
      "step": 5875
    },
    {
      "epoch": 1.1240236235473424,
      "grad_norm": 0.4773429334163666,
      "learning_rate": 0.0006273810282219532,
      "loss": 0.175,
      "step": 5900
    },
    {
      "epoch": 1.128786435511526,
      "grad_norm": 0.5828836560249329,
      "learning_rate": 0.0006257883672039243,
      "loss": 0.1929,
      "step": 5925
    },
    {
      "epoch": 1.1335492474757096,
      "grad_norm": 0.33104756474494934,
      "learning_rate": 0.0006241957061858954,
      "loss": 0.1725,
      "step": 5950
    },
    {
      "epoch": 1.1383120594398932,
      "grad_norm": 0.8148267269134521,
      "learning_rate": 0.0006226030451678665,
      "loss": 0.1593,
      "step": 5975
    },
    {
      "epoch": 1.143074871404077,
      "grad_norm": 0.5138137340545654,
      "learning_rate": 0.0006210103841498376,
      "loss": 0.1794,
      "step": 6000
    },
    {
      "epoch": 1.1478376833682606,
      "grad_norm": 0.3494833707809448,
      "learning_rate": 0.0006194177231318087,
      "loss": 0.183,
      "step": 6025
    },
    {
      "epoch": 1.1526004953324442,
      "grad_norm": 0.606903612613678,
      "learning_rate": 0.0006178250621137797,
      "loss": 0.1695,
      "step": 6050
    },
    {
      "epoch": 1.1573633072966278,
      "grad_norm": 0.47846776247024536,
      "learning_rate": 0.0006162324010957508,
      "loss": 0.171,
      "step": 6075
    },
    {
      "epoch": 1.1621261192608117,
      "grad_norm": 0.4595683217048645,
      "learning_rate": 0.0006146397400777218,
      "loss": 0.1816,
      "step": 6100
    },
    {
      "epoch": 1.1668889312249953,
      "grad_norm": 0.3711338937282562,
      "learning_rate": 0.000613047079059693,
      "loss": 0.1664,
      "step": 6125
    },
    {
      "epoch": 1.1716517431891789,
      "grad_norm": 0.3080506920814514,
      "learning_rate": 0.000611454418041664,
      "loss": 0.1758,
      "step": 6150
    },
    {
      "epoch": 1.1764145551533625,
      "grad_norm": 0.588534951210022,
      "learning_rate": 0.0006098617570236351,
      "loss": 0.1653,
      "step": 6175
    },
    {
      "epoch": 1.1811773671175463,
      "grad_norm": 0.5531810522079468,
      "learning_rate": 0.0006082690960056062,
      "loss": 0.1619,
      "step": 6200
    },
    {
      "epoch": 1.1859401790817299,
      "grad_norm": 0.6002033948898315,
      "learning_rate": 0.0006066764349875773,
      "loss": 0.1713,
      "step": 6225
    },
    {
      "epoch": 1.1907029910459135,
      "grad_norm": 0.354263573884964,
      "learning_rate": 0.0006050837739695482,
      "loss": 0.1501,
      "step": 6250
    },
    {
      "epoch": 1.195465803010097,
      "grad_norm": 0.32421377301216125,
      "learning_rate": 0.0006034911129515194,
      "loss": 0.1641,
      "step": 6275
    },
    {
      "epoch": 1.200228614974281,
      "grad_norm": 0.48651450872421265,
      "learning_rate": 0.0006018984519334904,
      "loss": 0.17,
      "step": 6300
    },
    {
      "epoch": 1.2049914269384645,
      "grad_norm": 0.3339197337627411,
      "learning_rate": 0.0006003057909154616,
      "loss": 0.1632,
      "step": 6325
    },
    {
      "epoch": 1.209754238902648,
      "grad_norm": 0.5121816992759705,
      "learning_rate": 0.0005987131298974326,
      "loss": 0.1643,
      "step": 6350
    },
    {
      "epoch": 1.2145170508668317,
      "grad_norm": 0.275868684053421,
      "learning_rate": 0.0005971204688794038,
      "loss": 0.18,
      "step": 6375
    },
    {
      "epoch": 1.2192798628310155,
      "grad_norm": 0.3451792001724243,
      "learning_rate": 0.0005955278078613748,
      "loss": 0.1719,
      "step": 6400
    },
    {
      "epoch": 1.2240426747951991,
      "grad_norm": 0.3716321289539337,
      "learning_rate": 0.0005939351468433458,
      "loss": 0.1725,
      "step": 6425
    },
    {
      "epoch": 1.2288054867593827,
      "grad_norm": 0.43131130933761597,
      "learning_rate": 0.0005923424858253169,
      "loss": 0.1454,
      "step": 6450
    },
    {
      "epoch": 1.2335682987235663,
      "grad_norm": 0.3478545546531677,
      "learning_rate": 0.000590749824807288,
      "loss": 0.156,
      "step": 6475
    },
    {
      "epoch": 1.2383311106877501,
      "grad_norm": 0.4298568665981293,
      "learning_rate": 0.000589157163789259,
      "loss": 0.1543,
      "step": 6500
    },
    {
      "epoch": 1.2430939226519337,
      "grad_norm": 0.4315966069698334,
      "learning_rate": 0.0005875645027712302,
      "loss": 0.1654,
      "step": 6525
    },
    {
      "epoch": 1.2478567346161173,
      "grad_norm": 0.5157601237297058,
      "learning_rate": 0.0005859718417532012,
      "loss": 0.1597,
      "step": 6550
    },
    {
      "epoch": 1.252619546580301,
      "grad_norm": 0.503664493560791,
      "learning_rate": 0.0005843791807351724,
      "loss": 0.1803,
      "step": 6575
    },
    {
      "epoch": 1.2573823585444845,
      "grad_norm": 0.2853633463382721,
      "learning_rate": 0.0005827865197171435,
      "loss": 0.1736,
      "step": 6600
    },
    {
      "epoch": 1.2621451705086684,
      "grad_norm": 0.46840670704841614,
      "learning_rate": 0.0005811938586991144,
      "loss": 0.1702,
      "step": 6625
    },
    {
      "epoch": 1.266907982472852,
      "grad_norm": 0.3835589587688446,
      "learning_rate": 0.0005796011976810856,
      "loss": 0.1724,
      "step": 6650
    },
    {
      "epoch": 1.2716707944370356,
      "grad_norm": 0.46621888875961304,
      "learning_rate": 0.0005780085366630566,
      "loss": 0.1614,
      "step": 6675
    },
    {
      "epoch": 1.2764336064012194,
      "grad_norm": 0.6573538184165955,
      "learning_rate": 0.0005764158756450278,
      "loss": 0.1678,
      "step": 6700
    },
    {
      "epoch": 1.281196418365403,
      "grad_norm": 0.4634212553501129,
      "learning_rate": 0.0005748232146269988,
      "loss": 0.1873,
      "step": 6725
    },
    {
      "epoch": 1.2859592303295866,
      "grad_norm": 0.48557624220848083,
      "learning_rate": 0.00057323055360897,
      "loss": 0.1669,
      "step": 6750
    },
    {
      "epoch": 1.2907220422937702,
      "grad_norm": 0.3482358157634735,
      "learning_rate": 0.000571637892590941,
      "loss": 0.1785,
      "step": 6775
    },
    {
      "epoch": 1.2954848542579538,
      "grad_norm": 0.46801701188087463,
      "learning_rate": 0.000570045231572912,
      "loss": 0.1751,
      "step": 6800
    },
    {
      "epoch": 1.3002476662221376,
      "grad_norm": 0.4743437170982361,
      "learning_rate": 0.0005684525705548831,
      "loss": 0.1742,
      "step": 6825
    },
    {
      "epoch": 1.3050104781863212,
      "grad_norm": 0.34174713492393494,
      "learning_rate": 0.0005668599095368542,
      "loss": 0.1821,
      "step": 6850
    },
    {
      "epoch": 1.3097732901505048,
      "grad_norm": 0.28029417991638184,
      "learning_rate": 0.0005652672485188253,
      "loss": 0.1826,
      "step": 6875
    },
    {
      "epoch": 1.3145361021146886,
      "grad_norm": 0.6575889587402344,
      "learning_rate": 0.0005636745875007964,
      "loss": 0.156,
      "step": 6900
    },
    {
      "epoch": 1.3192989140788722,
      "grad_norm": 0.4212856888771057,
      "learning_rate": 0.0005620819264827674,
      "loss": 0.1721,
      "step": 6925
    },
    {
      "epoch": 1.3240617260430558,
      "grad_norm": 0.27862221002578735,
      "learning_rate": 0.0005604892654647386,
      "loss": 0.1673,
      "step": 6950
    },
    {
      "epoch": 1.3288245380072394,
      "grad_norm": 0.46677640080451965,
      "learning_rate": 0.0005588966044467095,
      "loss": 0.1723,
      "step": 6975
    },
    {
      "epoch": 1.333587349971423,
      "grad_norm": 0.3922846019268036,
      "learning_rate": 0.0005573039434286807,
      "loss": 0.16,
      "step": 7000
    },
    {
      "epoch": 1.3383501619356069,
      "grad_norm": 0.37884360551834106,
      "learning_rate": 0.0005557112824106517,
      "loss": 0.1468,
      "step": 7025
    },
    {
      "epoch": 1.3431129738997905,
      "grad_norm": 0.4447380602359772,
      "learning_rate": 0.0005541186213926228,
      "loss": 0.1631,
      "step": 7050
    },
    {
      "epoch": 1.347875785863974,
      "grad_norm": 0.352593332529068,
      "learning_rate": 0.0005525259603745939,
      "loss": 0.1661,
      "step": 7075
    },
    {
      "epoch": 1.3526385978281579,
      "grad_norm": 0.48372286558151245,
      "learning_rate": 0.000550933299356565,
      "loss": 0.1584,
      "step": 7100
    },
    {
      "epoch": 1.3574014097923415,
      "grad_norm": 0.46954774856567383,
      "learning_rate": 0.000549340638338536,
      "loss": 0.159,
      "step": 7125
    },
    {
      "epoch": 1.362164221756525,
      "grad_norm": 0.34442412853240967,
      "learning_rate": 0.0005477479773205071,
      "loss": 0.1585,
      "step": 7150
    },
    {
      "epoch": 1.3669270337207087,
      "grad_norm": 0.49704864621162415,
      "learning_rate": 0.0005461553163024781,
      "loss": 0.1619,
      "step": 7175
    },
    {
      "epoch": 1.3716898456848923,
      "grad_norm": 0.38122478127479553,
      "learning_rate": 0.0005445626552844493,
      "loss": 0.16,
      "step": 7200
    },
    {
      "epoch": 1.376452657649076,
      "grad_norm": 0.30976754426956177,
      "learning_rate": 0.0005429699942664203,
      "loss": 0.1441,
      "step": 7225
    },
    {
      "epoch": 1.3812154696132597,
      "grad_norm": 0.3251299262046814,
      "learning_rate": 0.0005413773332483915,
      "loss": 0.1582,
      "step": 7250
    },
    {
      "epoch": 1.3859782815774433,
      "grad_norm": 0.32709449529647827,
      "learning_rate": 0.0005397846722303625,
      "loss": 0.1639,
      "step": 7275
    },
    {
      "epoch": 1.390741093541627,
      "grad_norm": 0.4007602632045746,
      "learning_rate": 0.0005381920112123336,
      "loss": 0.1536,
      "step": 7300
    },
    {
      "epoch": 1.3955039055058105,
      "grad_norm": 0.3978135883808136,
      "learning_rate": 0.0005365993501943046,
      "loss": 0.1663,
      "step": 7325
    },
    {
      "epoch": 1.4002667174699943,
      "grad_norm": 0.292554646730423,
      "learning_rate": 0.0005350066891762757,
      "loss": 0.1842,
      "step": 7350
    },
    {
      "epoch": 1.405029529434178,
      "grad_norm": 0.3876120150089264,
      "learning_rate": 0.0005334140281582469,
      "loss": 0.1742,
      "step": 7375
    },
    {
      "epoch": 1.4097923413983615,
      "grad_norm": 0.49505195021629333,
      "learning_rate": 0.0005318213671402179,
      "loss": 0.1711,
      "step": 7400
    },
    {
      "epoch": 1.4145551533625453,
      "grad_norm": 0.3360784649848938,
      "learning_rate": 0.000530228706122189,
      "loss": 0.1645,
      "step": 7425
    },
    {
      "epoch": 1.419317965326729,
      "grad_norm": 0.2553114593029022,
      "learning_rate": 0.0005286360451041601,
      "loss": 0.1452,
      "step": 7450
    },
    {
      "epoch": 1.4240807772909125,
      "grad_norm": 0.2878270447254181,
      "learning_rate": 0.0005270433840861312,
      "loss": 0.1636,
      "step": 7475
    },
    {
      "epoch": 1.4288435892550961,
      "grad_norm": 0.44745633006095886,
      "learning_rate": 0.0005254507230681021,
      "loss": 0.1418,
      "step": 7500
    },
    {
      "epoch": 1.4336064012192797,
      "grad_norm": 0.7947472929954529,
      "learning_rate": 0.0005238580620500733,
      "loss": 0.1722,
      "step": 7525
    },
    {
      "epoch": 1.4383692131834636,
      "grad_norm": 0.3430895209312439,
      "learning_rate": 0.0005222654010320443,
      "loss": 0.1631,
      "step": 7550
    },
    {
      "epoch": 1.4431320251476472,
      "grad_norm": 0.31936272978782654,
      "learning_rate": 0.0005206727400140155,
      "loss": 0.1534,
      "step": 7575
    },
    {
      "epoch": 1.4478948371118308,
      "grad_norm": 0.30465078353881836,
      "learning_rate": 0.0005190800789959865,
      "loss": 0.1519,
      "step": 7600
    },
    {
      "epoch": 1.4526576490760146,
      "grad_norm": 0.418100506067276,
      "learning_rate": 0.0005174874179779577,
      "loss": 0.1696,
      "step": 7625
    },
    {
      "epoch": 1.4574204610401982,
      "grad_norm": 0.31088781356811523,
      "learning_rate": 0.0005158947569599287,
      "loss": 0.1522,
      "step": 7650
    },
    {
      "epoch": 1.4621832730043818,
      "grad_norm": 0.3291206657886505,
      "learning_rate": 0.0005143020959418997,
      "loss": 0.1398,
      "step": 7675
    },
    {
      "epoch": 1.4669460849685654,
      "grad_norm": 0.5608575344085693,
      "learning_rate": 0.0005127094349238708,
      "loss": 0.1703,
      "step": 7700
    },
    {
      "epoch": 1.471708896932749,
      "grad_norm": 0.4119270443916321,
      "learning_rate": 0.0005111167739058419,
      "loss": 0.1494,
      "step": 7725
    },
    {
      "epoch": 1.4764717088969328,
      "grad_norm": 0.4103914201259613,
      "learning_rate": 0.0005095241128878129,
      "loss": 0.1572,
      "step": 7750
    },
    {
      "epoch": 1.4812345208611164,
      "grad_norm": 0.32199928164482117,
      "learning_rate": 0.0005079314518697841,
      "loss": 0.1482,
      "step": 7775
    },
    {
      "epoch": 1.4859973328253,
      "grad_norm": 0.3827882409095764,
      "learning_rate": 0.0005063387908517551,
      "loss": 0.1615,
      "step": 7800
    },
    {
      "epoch": 1.4907601447894838,
      "grad_norm": 0.5636634230613708,
      "learning_rate": 0.0005047461298337263,
      "loss": 0.1824,
      "step": 7825
    },
    {
      "epoch": 1.4955229567536674,
      "grad_norm": 0.3752606213092804,
      "learning_rate": 0.0005031534688156972,
      "loss": 0.1464,
      "step": 7850
    },
    {
      "epoch": 1.500285768717851,
      "grad_norm": 0.43356072902679443,
      "learning_rate": 0.0005015608077976683,
      "loss": 0.1395,
      "step": 7875
    },
    {
      "epoch": 1.5050485806820346,
      "grad_norm": 0.3378283977508545,
      "learning_rate": 0.0004999681467796394,
      "loss": 0.1551,
      "step": 7900
    },
    {
      "epoch": 1.5098113926462182,
      "grad_norm": 0.5155130624771118,
      "learning_rate": 0.0004983754857616105,
      "loss": 0.1493,
      "step": 7925
    },
    {
      "epoch": 1.514574204610402,
      "grad_norm": 0.4439029097557068,
      "learning_rate": 0.0004967828247435816,
      "loss": 0.1566,
      "step": 7950
    },
    {
      "epoch": 1.5193370165745856,
      "grad_norm": 0.3457154929637909,
      "learning_rate": 0.0004951901637255526,
      "loss": 0.1604,
      "step": 7975
    },
    {
      "epoch": 1.5240998285387692,
      "grad_norm": 0.4093439280986786,
      "learning_rate": 0.0004935975027075237,
      "loss": 0.147,
      "step": 8000
    },
    {
      "epoch": 1.528862640502953,
      "grad_norm": 0.39062246680259705,
      "learning_rate": 0.0004920048416894948,
      "loss": 0.1603,
      "step": 8025
    },
    {
      "epoch": 1.5336254524671364,
      "grad_norm": 0.4212568700313568,
      "learning_rate": 0.0004904121806714658,
      "loss": 0.1784,
      "step": 8050
    },
    {
      "epoch": 1.5383882644313203,
      "grad_norm": 0.5087997317314148,
      "learning_rate": 0.000488819519653437,
      "loss": 0.1734,
      "step": 8075
    },
    {
      "epoch": 1.5431510763955039,
      "grad_norm": 0.3535519242286682,
      "learning_rate": 0.00048722685863540805,
      "loss": 0.1322,
      "step": 8100
    },
    {
      "epoch": 1.5479138883596875,
      "grad_norm": 0.3052797317504883,
      "learning_rate": 0.00048563419761737915,
      "loss": 0.1622,
      "step": 8125
    },
    {
      "epoch": 1.5526767003238713,
      "grad_norm": 0.5136558413505554,
      "learning_rate": 0.0004840415365993502,
      "loss": 0.1461,
      "step": 8150
    },
    {
      "epoch": 1.5574395122880549,
      "grad_norm": 0.3127097487449646,
      "learning_rate": 0.0004824488755813213,
      "loss": 0.1546,
      "step": 8175
    },
    {
      "epoch": 1.5622023242522385,
      "grad_norm": 0.3706015944480896,
      "learning_rate": 0.00048085621456329236,
      "loss": 0.1676,
      "step": 8200
    },
    {
      "epoch": 1.5669651362164223,
      "grad_norm": 0.6944425106048584,
      "learning_rate": 0.0004792635535452634,
      "loss": 0.1436,
      "step": 8225
    },
    {
      "epoch": 1.5717279481806057,
      "grad_norm": 0.2767147421836853,
      "learning_rate": 0.0004776708925272345,
      "loss": 0.1492,
      "step": 8250
    },
    {
      "epoch": 1.5764907601447895,
      "grad_norm": 0.34188997745513916,
      "learning_rate": 0.0004760782315092056,
      "loss": 0.1566,
      "step": 8275
    },
    {
      "epoch": 1.581253572108973,
      "grad_norm": 0.4111349880695343,
      "learning_rate": 0.0004744855704911767,
      "loss": 0.1572,
      "step": 8300
    },
    {
      "epoch": 1.5860163840731567,
      "grad_norm": 0.3593684136867523,
      "learning_rate": 0.0004728929094731477,
      "loss": 0.1568,
      "step": 8325
    },
    {
      "epoch": 1.5907791960373405,
      "grad_norm": 0.3461627960205078,
      "learning_rate": 0.0004713002484551188,
      "loss": 0.1401,
      "step": 8350
    },
    {
      "epoch": 1.5955420080015241,
      "grad_norm": 0.41319209337234497,
      "learning_rate": 0.0004697075874370899,
      "loss": 0.1519,
      "step": 8375
    },
    {
      "epoch": 1.6003048199657077,
      "grad_norm": 0.3217964470386505,
      "learning_rate": 0.00046811492641906093,
      "loss": 0.1403,
      "step": 8400
    },
    {
      "epoch": 1.6050676319298915,
      "grad_norm": 1.6309716701507568,
      "learning_rate": 0.000466522265401032,
      "loss": 0.1395,
      "step": 8425
    },
    {
      "epoch": 1.609830443894075,
      "grad_norm": 0.31536224484443665,
      "learning_rate": 0.0004649296043830031,
      "loss": 0.1585,
      "step": 8450
    },
    {
      "epoch": 1.6145932558582587,
      "grad_norm": 0.3672066032886505,
      "learning_rate": 0.0004633369433649742,
      "loss": 0.1452,
      "step": 8475
    },
    {
      "epoch": 1.6193560678224423,
      "grad_norm": 0.32355138659477234,
      "learning_rate": 0.0004617442823469453,
      "loss": 0.1588,
      "step": 8500
    },
    {
      "epoch": 1.624118879786626,
      "grad_norm": 0.3850962519645691,
      "learning_rate": 0.0004601516213289164,
      "loss": 0.1581,
      "step": 8525
    },
    {
      "epoch": 1.6288816917508098,
      "grad_norm": 0.5192848443984985,
      "learning_rate": 0.0004585589603108875,
      "loss": 0.1606,
      "step": 8550
    },
    {
      "epoch": 1.6336445037149934,
      "grad_norm": 0.4034165143966675,
      "learning_rate": 0.00045696629929285856,
      "loss": 0.1515,
      "step": 8575
    },
    {
      "epoch": 1.638407315679177,
      "grad_norm": 0.24856723845005035,
      "learning_rate": 0.0004553736382748296,
      "loss": 0.1689,
      "step": 8600
    },
    {
      "epoch": 1.6431701276433608,
      "grad_norm": 0.7013080716133118,
      "learning_rate": 0.0004537809772568007,
      "loss": 0.1642,
      "step": 8625
    },
    {
      "epoch": 1.6479329396075442,
      "grad_norm": 0.32498759031295776,
      "learning_rate": 0.0004521883162387718,
      "loss": 0.1621,
      "step": 8650
    },
    {
      "epoch": 1.652695751571728,
      "grad_norm": 0.3156094253063202,
      "learning_rate": 0.0004505956552207428,
      "loss": 0.1511,
      "step": 8675
    },
    {
      "epoch": 1.6574585635359116,
      "grad_norm": 0.4911789298057556,
      "learning_rate": 0.0004490029942027139,
      "loss": 0.1635,
      "step": 8700
    },
    {
      "epoch": 1.6622213755000952,
      "grad_norm": 0.5501715540885925,
      "learning_rate": 0.000447410333184685,
      "loss": 0.1388,
      "step": 8725
    },
    {
      "epoch": 1.666984187464279,
      "grad_norm": 0.45334193110466003,
      "learning_rate": 0.0004458176721666561,
      "loss": 0.1537,
      "step": 8750
    },
    {
      "epoch": 1.6717469994284626,
      "grad_norm": 0.5237213969230652,
      "learning_rate": 0.00044422501114862713,
      "loss": 0.1475,
      "step": 8775
    },
    {
      "epoch": 1.6765098113926462,
      "grad_norm": 0.5325502753257751,
      "learning_rate": 0.0004426323501305982,
      "loss": 0.1355,
      "step": 8800
    },
    {
      "epoch": 1.68127262335683,
      "grad_norm": 1.950467824935913,
      "learning_rate": 0.0004410396891125693,
      "loss": 0.1375,
      "step": 8825
    },
    {
      "epoch": 1.6860354353210134,
      "grad_norm": 0.47218066453933716,
      "learning_rate": 0.00043944702809454035,
      "loss": 0.1468,
      "step": 8850
    },
    {
      "epoch": 1.6907982472851972,
      "grad_norm": 0.5059038996696472,
      "learning_rate": 0.00043785436707651144,
      "loss": 0.1516,
      "step": 8875
    },
    {
      "epoch": 1.6955610592493808,
      "grad_norm": 0.3512662351131439,
      "learning_rate": 0.00043626170605848253,
      "loss": 0.1638,
      "step": 8900
    },
    {
      "epoch": 1.7003238712135644,
      "grad_norm": 0.3385744094848633,
      "learning_rate": 0.0004346690450404536,
      "loss": 0.1356,
      "step": 8925
    },
    {
      "epoch": 1.7050866831777483,
      "grad_norm": 0.33207762241363525,
      "learning_rate": 0.00043307638402242466,
      "loss": 0.1596,
      "step": 8950
    },
    {
      "epoch": 1.7098494951419316,
      "grad_norm": 0.4162212312221527,
      "learning_rate": 0.00043148372300439575,
      "loss": 0.1438,
      "step": 8975
    },
    {
      "epoch": 1.7146123071061155,
      "grad_norm": 0.3793085813522339,
      "learning_rate": 0.000429954768427088,
      "loss": 0.1544,
      "step": 9000
    },
    {
      "epoch": 1.719375119070299,
      "grad_norm": 0.25957417488098145,
      "learning_rate": 0.0004283621074090591,
      "loss": 0.1562,
      "step": 9025
    },
    {
      "epoch": 1.7241379310344827,
      "grad_norm": 0.3840574622154236,
      "learning_rate": 0.00042676944639103017,
      "loss": 0.1635,
      "step": 9050
    },
    {
      "epoch": 1.7289007429986665,
      "grad_norm": 0.3600490689277649,
      "learning_rate": 0.0004251767853730012,
      "loss": 0.1481,
      "step": 9075
    },
    {
      "epoch": 1.73366355496285,
      "grad_norm": 0.33807894587516785,
      "learning_rate": 0.0004235841243549723,
      "loss": 0.1641,
      "step": 9100
    },
    {
      "epoch": 1.7384263669270337,
      "grad_norm": 0.4133497178554535,
      "learning_rate": 0.0004219914633369434,
      "loss": 0.1587,
      "step": 9125
    },
    {
      "epoch": 1.7431891788912175,
      "grad_norm": 0.7563489675521851,
      "learning_rate": 0.0004203988023189145,
      "loss": 0.1602,
      "step": 9150
    },
    {
      "epoch": 1.7479519908554009,
      "grad_norm": 0.36141237616539,
      "learning_rate": 0.0004188061413008855,
      "loss": 0.1492,
      "step": 9175
    },
    {
      "epoch": 1.7527148028195847,
      "grad_norm": 0.5030120611190796,
      "learning_rate": 0.0004172134802828566,
      "loss": 0.1491,
      "step": 9200
    },
    {
      "epoch": 1.7574776147837683,
      "grad_norm": 0.47502759099006653,
      "learning_rate": 0.0004156208192648277,
      "loss": 0.1574,
      "step": 9225
    },
    {
      "epoch": 1.762240426747952,
      "grad_norm": 0.4632207751274109,
      "learning_rate": 0.00041402815824679874,
      "loss": 0.1682,
      "step": 9250
    },
    {
      "epoch": 1.7670032387121357,
      "grad_norm": 0.49272143840789795,
      "learning_rate": 0.0004124354972287698,
      "loss": 0.1541,
      "step": 9275
    },
    {
      "epoch": 1.7717660506763193,
      "grad_norm": 0.2834301292896271,
      "learning_rate": 0.0004108428362107409,
      "loss": 0.1466,
      "step": 9300
    },
    {
      "epoch": 1.776528862640503,
      "grad_norm": 0.4585048258304596,
      "learning_rate": 0.000409250175192712,
      "loss": 0.1517,
      "step": 9325
    },
    {
      "epoch": 1.7812916746046867,
      "grad_norm": 0.382061243057251,
      "learning_rate": 0.00040765751417468305,
      "loss": 0.1438,
      "step": 9350
    },
    {
      "epoch": 1.7860544865688701,
      "grad_norm": 0.3742637038230896,
      "learning_rate": 0.00040606485315665414,
      "loss": 0.1344,
      "step": 9375
    },
    {
      "epoch": 1.790817298533054,
      "grad_norm": 0.2998879551887512,
      "learning_rate": 0.0004044721921386252,
      "loss": 0.1338,
      "step": 9400
    },
    {
      "epoch": 1.7955801104972375,
      "grad_norm": 0.3811677396297455,
      "learning_rate": 0.00040287953112059626,
      "loss": 0.1447,
      "step": 9425
    },
    {
      "epoch": 1.8003429224614211,
      "grad_norm": 0.35961025953292847,
      "learning_rate": 0.00040128687010256735,
      "loss": 0.1373,
      "step": 9450
    },
    {
      "epoch": 1.805105734425605,
      "grad_norm": 0.40483054518699646,
      "learning_rate": 0.00039969420908453845,
      "loss": 0.1456,
      "step": 9475
    },
    {
      "epoch": 1.8098685463897886,
      "grad_norm": 0.2703985273838043,
      "learning_rate": 0.00039810154806650954,
      "loss": 0.1478,
      "step": 9500
    },
    {
      "epoch": 1.8146313583539722,
      "grad_norm": 0.47140568494796753,
      "learning_rate": 0.0003965088870484806,
      "loss": 0.1536,
      "step": 9525
    },
    {
      "epoch": 1.819394170318156,
      "grad_norm": 0.4907878637313843,
      "learning_rate": 0.00039491622603045166,
      "loss": 0.1503,
      "step": 9550
    },
    {
      "epoch": 1.8241569822823394,
      "grad_norm": 0.4391274154186249,
      "learning_rate": 0.00039332356501242276,
      "loss": 0.1383,
      "step": 9575
    },
    {
      "epoch": 1.8289197942465232,
      "grad_norm": 0.3573954105377197,
      "learning_rate": 0.0003917309039943938,
      "loss": 0.1485,
      "step": 9600
    },
    {
      "epoch": 1.8336826062107068,
      "grad_norm": 0.39075174927711487,
      "learning_rate": 0.00039013824297636494,
      "loss": 0.144,
      "step": 9625
    },
    {
      "epoch": 1.8384454181748904,
      "grad_norm": 0.3976086378097534,
      "learning_rate": 0.00038854558195833603,
      "loss": 0.1428,
      "step": 9650
    },
    {
      "epoch": 1.8432082301390742,
      "grad_norm": 0.6332001090049744,
      "learning_rate": 0.0003869529209403071,
      "loss": 0.1444,
      "step": 9675
    },
    {
      "epoch": 1.8479710421032578,
      "grad_norm": 0.3278062045574188,
      "learning_rate": 0.00038536025992227816,
      "loss": 0.157,
      "step": 9700
    },
    {
      "epoch": 1.8527338540674414,
      "grad_norm": 0.4466111958026886,
      "learning_rate": 0.00038376759890424925,
      "loss": 0.1469,
      "step": 9725
    },
    {
      "epoch": 1.8574966660316252,
      "grad_norm": 0.533725917339325,
      "learning_rate": 0.00038217493788622034,
      "loss": 0.1538,
      "step": 9750
    },
    {
      "epoch": 1.8622594779958086,
      "grad_norm": 0.371269166469574,
      "learning_rate": 0.0003805822768681914,
      "loss": 0.1372,
      "step": 9775
    },
    {
      "epoch": 1.8670222899599924,
      "grad_norm": 0.34528669714927673,
      "learning_rate": 0.00037898961585016246,
      "loss": 0.1495,
      "step": 9800
    },
    {
      "epoch": 1.871785101924176,
      "grad_norm": 0.32617661356925964,
      "learning_rate": 0.00037739695483213356,
      "loss": 0.141,
      "step": 9825
    },
    {
      "epoch": 1.8765479138883596,
      "grad_norm": 0.3971022367477417,
      "learning_rate": 0.00037580429381410465,
      "loss": 0.1236,
      "step": 9850
    },
    {
      "epoch": 1.8813107258525434,
      "grad_norm": 0.4165213406085968,
      "learning_rate": 0.0003742116327960757,
      "loss": 0.1713,
      "step": 9875
    },
    {
      "epoch": 1.886073537816727,
      "grad_norm": 0.59468013048172,
      "learning_rate": 0.0003726189717780468,
      "loss": 0.1433,
      "step": 9900
    },
    {
      "epoch": 1.8908363497809106,
      "grad_norm": 0.3666245639324188,
      "learning_rate": 0.00037102631076001787,
      "loss": 0.1359,
      "step": 9925
    },
    {
      "epoch": 1.8955991617450945,
      "grad_norm": 0.317894846200943,
      "learning_rate": 0.0003694336497419889,
      "loss": 0.1524,
      "step": 9950
    },
    {
      "epoch": 1.9003619737092778,
      "grad_norm": 0.3837354779243469,
      "learning_rate": 0.00036784098872396,
      "loss": 0.1595,
      "step": 9975
    },
    {
      "epoch": 1.9051247856734617,
      "grad_norm": 0.3772681653499603,
      "learning_rate": 0.0003662483277059311,
      "loss": 0.1646,
      "step": 10000
    },
    {
      "epoch": 1.9098875976376453,
      "grad_norm": 0.5626959800720215,
      "learning_rate": 0.0003646556666879022,
      "loss": 0.1381,
      "step": 10025
    },
    {
      "epoch": 1.9146504096018289,
      "grad_norm": 0.34700676798820496,
      "learning_rate": 0.0003630630056698732,
      "loss": 0.1585,
      "step": 10050
    },
    {
      "epoch": 1.9194132215660127,
      "grad_norm": 0.33007413148880005,
      "learning_rate": 0.0003614703446518443,
      "loss": 0.1611,
      "step": 10075
    },
    {
      "epoch": 1.924176033530196,
      "grad_norm": 0.45671606063842773,
      "learning_rate": 0.0003598776836338154,
      "loss": 0.1442,
      "step": 10100
    },
    {
      "epoch": 1.9289388454943799,
      "grad_norm": 0.28360098600387573,
      "learning_rate": 0.00035828502261578643,
      "loss": 0.1501,
      "step": 10125
    },
    {
      "epoch": 1.9337016574585635,
      "grad_norm": 0.34439265727996826,
      "learning_rate": 0.0003566923615977575,
      "loss": 0.134,
      "step": 10150
    },
    {
      "epoch": 1.938464469422747,
      "grad_norm": 0.4307344853878021,
      "learning_rate": 0.0003550997005797286,
      "loss": 0.156,
      "step": 10175
    },
    {
      "epoch": 1.943227281386931,
      "grad_norm": 0.3773944079875946,
      "learning_rate": 0.0003535070395616997,
      "loss": 0.1491,
      "step": 10200
    },
    {
      "epoch": 1.9479900933511145,
      "grad_norm": 0.31953540444374084,
      "learning_rate": 0.00035191437854367074,
      "loss": 0.1507,
      "step": 10225
    },
    {
      "epoch": 1.952752905315298,
      "grad_norm": 0.5001490116119385,
      "learning_rate": 0.00035032171752564183,
      "loss": 0.1505,
      "step": 10250
    },
    {
      "epoch": 1.957515717279482,
      "grad_norm": 0.3133102059364319,
      "learning_rate": 0.0003487290565076129,
      "loss": 0.1459,
      "step": 10275
    },
    {
      "epoch": 1.9622785292436653,
      "grad_norm": 0.6702970266342163,
      "learning_rate": 0.00034713639548958396,
      "loss": 0.1431,
      "step": 10300
    },
    {
      "epoch": 1.9670413412078491,
      "grad_norm": 0.4450147747993469,
      "learning_rate": 0.00034554373447155505,
      "loss": 0.1403,
      "step": 10325
    },
    {
      "epoch": 1.9718041531720327,
      "grad_norm": 0.34403184056282043,
      "learning_rate": 0.00034395107345352614,
      "loss": 0.1296,
      "step": 10350
    },
    {
      "epoch": 1.9765669651362163,
      "grad_norm": 0.31004440784454346,
      "learning_rate": 0.00034235841243549723,
      "loss": 0.1414,
      "step": 10375
    },
    {
      "epoch": 1.9813297771004001,
      "grad_norm": 0.29344800114631653,
      "learning_rate": 0.0003407657514174683,
      "loss": 0.134,
      "step": 10400
    },
    {
      "epoch": 1.9860925890645837,
      "grad_norm": 0.3132372796535492,
      "learning_rate": 0.0003391730903994394,
      "loss": 0.1352,
      "step": 10425
    },
    {
      "epoch": 1.9908554010287673,
      "grad_norm": 0.5730715990066528,
      "learning_rate": 0.0003375804293814105,
      "loss": 0.1368,
      "step": 10450
    },
    {
      "epoch": 1.9956182129929512,
      "grad_norm": 0.31889814138412476,
      "learning_rate": 0.00033598776836338154,
      "loss": 0.1428,
      "step": 10475
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.14948680996894836,
      "eval_runtime": 3792.2926,
      "eval_samples_per_second": 5.272,
      "eval_steps_per_second": 0.659,
      "step": 10498
    },
    {
      "epoch": 2.0003810249571345,
      "grad_norm": 0.42295727133750916,
      "learning_rate": 0.00033439510734535263,
      "loss": 0.1336,
      "step": 10500
    },
    {
      "epoch": 2.0051438369213184,
      "grad_norm": 0.3503652811050415,
      "learning_rate": 0.0003328024463273237,
      "loss": 0.1151,
      "step": 10525
    },
    {
      "epoch": 2.009906648885502,
      "grad_norm": 0.306481271982193,
      "learning_rate": 0.0003312097853092948,
      "loss": 0.1179,
      "step": 10550
    },
    {
      "epoch": 2.0146694608496856,
      "grad_norm": 0.36294692754745483,
      "learning_rate": 0.00032961712429126585,
      "loss": 0.1104,
      "step": 10575
    },
    {
      "epoch": 2.0194322728138694,
      "grad_norm": 0.3247184753417969,
      "learning_rate": 0.00032802446327323694,
      "loss": 0.1155,
      "step": 10600
    },
    {
      "epoch": 2.0241950847780528,
      "grad_norm": 0.32534146308898926,
      "learning_rate": 0.00032643180225520803,
      "loss": 0.096,
      "step": 10625
    },
    {
      "epoch": 2.0289578967422366,
      "grad_norm": 0.5160256624221802,
      "learning_rate": 0.00032483914123717907,
      "loss": 0.1216,
      "step": 10650
    },
    {
      "epoch": 2.0337207087064204,
      "grad_norm": 0.3254968822002411,
      "learning_rate": 0.00032324648021915016,
      "loss": 0.1215,
      "step": 10675
    },
    {
      "epoch": 2.038483520670604,
      "grad_norm": 0.313993364572525,
      "learning_rate": 0.00032165381920112125,
      "loss": 0.1065,
      "step": 10700
    },
    {
      "epoch": 2.0432463326347876,
      "grad_norm": 0.30261147022247314,
      "learning_rate": 0.00032006115818309234,
      "loss": 0.1156,
      "step": 10725
    },
    {
      "epoch": 2.0480091445989714,
      "grad_norm": 0.34677785634994507,
      "learning_rate": 0.0003184684971650634,
      "loss": 0.1107,
      "step": 10750
    },
    {
      "epoch": 2.052771956563155,
      "grad_norm": 0.3280388116836548,
      "learning_rate": 0.00031687583614703447,
      "loss": 0.1095,
      "step": 10775
    },
    {
      "epoch": 2.0575347685273386,
      "grad_norm": 0.31292206048965454,
      "learning_rate": 0.00031528317512900556,
      "loss": 0.113,
      "step": 10800
    },
    {
      "epoch": 2.062297580491522,
      "grad_norm": 0.30087533593177795,
      "learning_rate": 0.0003136905141109766,
      "loss": 0.1139,
      "step": 10825
    },
    {
      "epoch": 2.067060392455706,
      "grad_norm": 0.5178866386413574,
      "learning_rate": 0.0003120978530929477,
      "loss": 0.1098,
      "step": 10850
    },
    {
      "epoch": 2.0718232044198897,
      "grad_norm": 0.3406858444213867,
      "learning_rate": 0.0003105051920749188,
      "loss": 0.1178,
      "step": 10875
    },
    {
      "epoch": 2.076586016384073,
      "grad_norm": 0.4048568904399872,
      "learning_rate": 0.00030891253105688987,
      "loss": 0.1133,
      "step": 10900
    },
    {
      "epoch": 2.081348828348257,
      "grad_norm": 0.33406156301498413,
      "learning_rate": 0.0003073198700388609,
      "loss": 0.1132,
      "step": 10925
    },
    {
      "epoch": 2.0861116403124407,
      "grad_norm": 0.31882405281066895,
      "learning_rate": 0.000305727209020832,
      "loss": 0.1183,
      "step": 10950
    },
    {
      "epoch": 2.090874452276624,
      "grad_norm": 0.3499593138694763,
      "learning_rate": 0.0003041345480028031,
      "loss": 0.1143,
      "step": 10975
    },
    {
      "epoch": 2.095637264240808,
      "grad_norm": 0.30470743775367737,
      "learning_rate": 0.0003025418869847741,
      "loss": 0.112,
      "step": 11000
    },
    {
      "epoch": 2.1004000762049913,
      "grad_norm": 0.40244147181510925,
      "learning_rate": 0.0003009492259667452,
      "loss": 0.1139,
      "step": 11025
    },
    {
      "epoch": 2.105162888169175,
      "grad_norm": 0.3321830630302429,
      "learning_rate": 0.0002993565649487163,
      "loss": 0.1021,
      "step": 11050
    },
    {
      "epoch": 2.109925700133359,
      "grad_norm": 0.31888747215270996,
      "learning_rate": 0.0002977639039306874,
      "loss": 0.098,
      "step": 11075
    },
    {
      "epoch": 2.1146885120975423,
      "grad_norm": 0.26630911231040955,
      "learning_rate": 0.00029617124291265843,
      "loss": 0.1073,
      "step": 11100
    },
    {
      "epoch": 2.119451324061726,
      "grad_norm": 0.5243715047836304,
      "learning_rate": 0.0002945785818946295,
      "loss": 0.1086,
      "step": 11125
    },
    {
      "epoch": 2.12421413602591,
      "grad_norm": 0.30697929859161377,
      "learning_rate": 0.0002929859208766006,
      "loss": 0.1067,
      "step": 11150
    },
    {
      "epoch": 2.1289769479900933,
      "grad_norm": 0.39677879214286804,
      "learning_rate": 0.00029139325985857176,
      "loss": 0.1053,
      "step": 11175
    },
    {
      "epoch": 2.133739759954277,
      "grad_norm": 0.322727233171463,
      "learning_rate": 0.0002898005988405428,
      "loss": 0.1078,
      "step": 11200
    },
    {
      "epoch": 2.1385025719184605,
      "grad_norm": 0.33172428607940674,
      "learning_rate": 0.0002882079378225139,
      "loss": 0.1127,
      "step": 11225
    },
    {
      "epoch": 2.1432653838826443,
      "grad_norm": 0.8362516760826111,
      "learning_rate": 0.000286615276804485,
      "loss": 0.1095,
      "step": 11250
    },
    {
      "epoch": 2.148028195846828,
      "grad_norm": 0.2842552363872528,
      "learning_rate": 0.000285022615786456,
      "loss": 0.1052,
      "step": 11275
    },
    {
      "epoch": 2.1527910078110115,
      "grad_norm": 0.3666055202484131,
      "learning_rate": 0.0002834299547684271,
      "loss": 0.1073,
      "step": 11300
    },
    {
      "epoch": 2.1575538197751953,
      "grad_norm": 0.2301405668258667,
      "learning_rate": 0.0002818372937503982,
      "loss": 0.1102,
      "step": 11325
    },
    {
      "epoch": 2.1623166317393787,
      "grad_norm": 0.4762822389602661,
      "learning_rate": 0.0002802446327323693,
      "loss": 0.1225,
      "step": 11350
    },
    {
      "epoch": 2.1670794437035625,
      "grad_norm": 0.3253151774406433,
      "learning_rate": 0.0002786519717143403,
      "loss": 0.1093,
      "step": 11375
    },
    {
      "epoch": 2.1718422556677464,
      "grad_norm": 0.23877106606960297,
      "learning_rate": 0.0002770593106963114,
      "loss": 0.1096,
      "step": 11400
    },
    {
      "epoch": 2.1766050676319297,
      "grad_norm": 0.3996235728263855,
      "learning_rate": 0.0002754666496782825,
      "loss": 0.1143,
      "step": 11425
    },
    {
      "epoch": 2.1813678795961136,
      "grad_norm": 0.38844043016433716,
      "learning_rate": 0.00027387398866025354,
      "loss": 0.1259,
      "step": 11450
    },
    {
      "epoch": 2.1861306915602974,
      "grad_norm": 0.31765761971473694,
      "learning_rate": 0.00027228132764222463,
      "loss": 0.1081,
      "step": 11475
    },
    {
      "epoch": 2.1908935035244808,
      "grad_norm": 0.2910570502281189,
      "learning_rate": 0.0002706886666241957,
      "loss": 0.1085,
      "step": 11500
    },
    {
      "epoch": 2.1956563154886646,
      "grad_norm": 0.33713698387145996,
      "learning_rate": 0.0002690960056061668,
      "loss": 0.1096,
      "step": 11525
    },
    {
      "epoch": 2.200419127452848,
      "grad_norm": 0.33792057633399963,
      "learning_rate": 0.00026750334458813785,
      "loss": 0.108,
      "step": 11550
    },
    {
      "epoch": 2.2051819394170318,
      "grad_norm": 0.37385690212249756,
      "learning_rate": 0.00026591068357010894,
      "loss": 0.1016,
      "step": 11575
    },
    {
      "epoch": 2.2099447513812156,
      "grad_norm": 0.4146036207675934,
      "learning_rate": 0.00026431802255208004,
      "loss": 0.119,
      "step": 11600
    },
    {
      "epoch": 2.214707563345399,
      "grad_norm": 0.22132256627082825,
      "learning_rate": 0.00026272536153405107,
      "loss": 0.1181,
      "step": 11625
    },
    {
      "epoch": 2.219470375309583,
      "grad_norm": 0.3641311526298523,
      "learning_rate": 0.00026113270051602216,
      "loss": 0.1015,
      "step": 11650
    },
    {
      "epoch": 2.2242331872737666,
      "grad_norm": 0.30090126395225525,
      "learning_rate": 0.00025954003949799325,
      "loss": 0.1074,
      "step": 11675
    },
    {
      "epoch": 2.22899599923795,
      "grad_norm": 0.4461182653903961,
      "learning_rate": 0.00025794737847996434,
      "loss": 0.092,
      "step": 11700
    },
    {
      "epoch": 2.233758811202134,
      "grad_norm": 0.6503050923347473,
      "learning_rate": 0.0002563547174619354,
      "loss": 0.1251,
      "step": 11725
    },
    {
      "epoch": 2.238521623166317,
      "grad_norm": 0.2613127827644348,
      "learning_rate": 0.00025476205644390647,
      "loss": 0.1029,
      "step": 11750
    },
    {
      "epoch": 2.243284435130501,
      "grad_norm": 0.3186246454715729,
      "learning_rate": 0.00025316939542587756,
      "loss": 0.119,
      "step": 11775
    },
    {
      "epoch": 2.248047247094685,
      "grad_norm": 0.36391136050224304,
      "learning_rate": 0.0002515767344078486,
      "loss": 0.101,
      "step": 11800
    },
    {
      "epoch": 2.252810059058868,
      "grad_norm": 0.4605730175971985,
      "learning_rate": 0.0002499840733898197,
      "loss": 0.1043,
      "step": 11825
    },
    {
      "epoch": 2.257572871023052,
      "grad_norm": 0.23424066603183746,
      "learning_rate": 0.0002483914123717908,
      "loss": 0.1151,
      "step": 11850
    },
    {
      "epoch": 2.262335682987236,
      "grad_norm": 0.29857316613197327,
      "learning_rate": 0.00024679875135376187,
      "loss": 0.1062,
      "step": 11875
    },
    {
      "epoch": 2.2670984949514192,
      "grad_norm": 0.2949349284172058,
      "learning_rate": 0.0002452060903357329,
      "loss": 0.1068,
      "step": 11900
    },
    {
      "epoch": 2.271861306915603,
      "grad_norm": 0.2792544364929199,
      "learning_rate": 0.00024361342931770403,
      "loss": 0.1008,
      "step": 11925
    },
    {
      "epoch": 2.2766241188797864,
      "grad_norm": 0.5156565308570862,
      "learning_rate": 0.0002420207682996751,
      "loss": 0.1065,
      "step": 11950
    },
    {
      "epoch": 2.2813869308439703,
      "grad_norm": 0.25770053267478943,
      "learning_rate": 0.00024042810728164618,
      "loss": 0.1149,
      "step": 11975
    },
    {
      "epoch": 2.286149742808154,
      "grad_norm": 0.3577715754508972,
      "learning_rate": 0.00023883544626361725,
      "loss": 0.1054,
      "step": 12000
    },
    {
      "epoch": 2.2909125547723375,
      "grad_norm": 0.31701961159706116,
      "learning_rate": 0.00023724278524558834,
      "loss": 0.1064,
      "step": 12025
    },
    {
      "epoch": 2.2956753667365213,
      "grad_norm": 0.3124876022338867,
      "learning_rate": 0.0002356501242275594,
      "loss": 0.1152,
      "step": 12050
    },
    {
      "epoch": 2.3004381787007047,
      "grad_norm": 0.3948792815208435,
      "learning_rate": 0.00023405746320953046,
      "loss": 0.1103,
      "step": 12075
    },
    {
      "epoch": 2.3052009906648885,
      "grad_norm": 0.2156212031841278,
      "learning_rate": 0.00023246480219150156,
      "loss": 0.1115,
      "step": 12100
    },
    {
      "epoch": 2.3099638026290723,
      "grad_norm": 0.2897696793079376,
      "learning_rate": 0.00023087214117347265,
      "loss": 0.1127,
      "step": 12125
    },
    {
      "epoch": 2.3147266145932557,
      "grad_norm": 0.4053252339363098,
      "learning_rate": 0.0002293431865961649,
      "loss": 0.1078,
      "step": 12150
    },
    {
      "epoch": 2.3194894265574395,
      "grad_norm": 0.372749000787735,
      "learning_rate": 0.00022775052557813595,
      "loss": 0.1045,
      "step": 12175
    },
    {
      "epoch": 2.3242522385216233,
      "grad_norm": 0.1908310353755951,
      "learning_rate": 0.00022615786456010704,
      "loss": 0.1069,
      "step": 12200
    },
    {
      "epoch": 2.3290150504858067,
      "grad_norm": 0.3501359224319458,
      "learning_rate": 0.0002245652035420781,
      "loss": 0.1037,
      "step": 12225
    },
    {
      "epoch": 2.3337778624499905,
      "grad_norm": 0.24297595024108887,
      "learning_rate": 0.0002229725425240492,
      "loss": 0.1045,
      "step": 12250
    },
    {
      "epoch": 2.3385406744141743,
      "grad_norm": 0.29775258898735046,
      "learning_rate": 0.00022137988150602026,
      "loss": 0.1056,
      "step": 12275
    },
    {
      "epoch": 2.3433034863783577,
      "grad_norm": 0.3680590093135834,
      "learning_rate": 0.00021978722048799135,
      "loss": 0.1031,
      "step": 12300
    },
    {
      "epoch": 2.3480662983425415,
      "grad_norm": 0.3231523931026459,
      "learning_rate": 0.00021819455946996241,
      "loss": 0.1041,
      "step": 12325
    },
    {
      "epoch": 2.352829110306725,
      "grad_norm": 0.379346638917923,
      "learning_rate": 0.00021660189845193348,
      "loss": 0.1126,
      "step": 12350
    },
    {
      "epoch": 2.3575919222709087,
      "grad_norm": 0.44511309266090393,
      "learning_rate": 0.00021500923743390457,
      "loss": 0.105,
      "step": 12375
    },
    {
      "epoch": 2.3623547342350926,
      "grad_norm": 0.3124861717224121,
      "learning_rate": 0.00021341657641587563,
      "loss": 0.1013,
      "step": 12400
    },
    {
      "epoch": 2.367117546199276,
      "grad_norm": 0.4290178418159485,
      "learning_rate": 0.00021182391539784672,
      "loss": 0.103,
      "step": 12425
    },
    {
      "epoch": 2.3718803581634598,
      "grad_norm": 0.3707790970802307,
      "learning_rate": 0.0002102312543798178,
      "loss": 0.1032,
      "step": 12450
    },
    {
      "epoch": 2.376643170127643,
      "grad_norm": 0.5477215647697449,
      "learning_rate": 0.00020863859336178888,
      "loss": 0.1015,
      "step": 12475
    },
    {
      "epoch": 2.381405982091827,
      "grad_norm": 0.3387431204319,
      "learning_rate": 0.00020704593234375997,
      "loss": 0.1044,
      "step": 12500
    },
    {
      "epoch": 2.386168794056011,
      "grad_norm": 0.41811680793762207,
      "learning_rate": 0.00020545327132573103,
      "loss": 0.1098,
      "step": 12525
    },
    {
      "epoch": 2.390931606020194,
      "grad_norm": 0.31459683179855347,
      "learning_rate": 0.00020386061030770212,
      "loss": 0.1033,
      "step": 12550
    },
    {
      "epoch": 2.395694417984378,
      "grad_norm": 0.40594083070755005,
      "learning_rate": 0.0002022679492896732,
      "loss": 0.1026,
      "step": 12575
    },
    {
      "epoch": 2.400457229948562,
      "grad_norm": 0.3358421325683594,
      "learning_rate": 0.00020067528827164428,
      "loss": 0.1091,
      "step": 12600
    },
    {
      "epoch": 2.405220041912745,
      "grad_norm": 0.40944692492485046,
      "learning_rate": 0.00019908262725361534,
      "loss": 0.0892,
      "step": 12625
    },
    {
      "epoch": 2.409982853876929,
      "grad_norm": 0.22119440138339996,
      "learning_rate": 0.00019748996623558643,
      "loss": 0.098,
      "step": 12650
    },
    {
      "epoch": 2.414745665841113,
      "grad_norm": 0.19652560353279114,
      "learning_rate": 0.0001958973052175575,
      "loss": 0.0987,
      "step": 12675
    },
    {
      "epoch": 2.419508477805296,
      "grad_norm": 0.2012779414653778,
      "learning_rate": 0.00019430464419952856,
      "loss": 0.1124,
      "step": 12700
    },
    {
      "epoch": 2.42427128976948,
      "grad_norm": 0.3495592772960663,
      "learning_rate": 0.00019271198318149965,
      "loss": 0.1013,
      "step": 12725
    },
    {
      "epoch": 2.4290341017336634,
      "grad_norm": 0.4101680517196655,
      "learning_rate": 0.00019111932216347072,
      "loss": 0.1034,
      "step": 12750
    },
    {
      "epoch": 2.4337969136978472,
      "grad_norm": 0.46700823307037354,
      "learning_rate": 0.0001895266611454418,
      "loss": 0.1025,
      "step": 12775
    },
    {
      "epoch": 2.438559725662031,
      "grad_norm": 0.37101560831069946,
      "learning_rate": 0.00018793400012741287,
      "loss": 0.1116,
      "step": 12800
    },
    {
      "epoch": 2.4433225376262144,
      "grad_norm": 0.26723676919937134,
      "learning_rate": 0.00018634133910938396,
      "loss": 0.0905,
      "step": 12825
    },
    {
      "epoch": 2.4480853495903983,
      "grad_norm": 0.41940173506736755,
      "learning_rate": 0.00018474867809135503,
      "loss": 0.1033,
      "step": 12850
    },
    {
      "epoch": 2.4528481615545816,
      "grad_norm": 0.3671918511390686,
      "learning_rate": 0.00018315601707332612,
      "loss": 0.1031,
      "step": 12875
    },
    {
      "epoch": 2.4576109735187655,
      "grad_norm": 0.4865685999393463,
      "learning_rate": 0.0001815633560552972,
      "loss": 0.0883,
      "step": 12900
    },
    {
      "epoch": 2.4623737854829493,
      "grad_norm": 0.4814120829105377,
      "learning_rate": 0.00017997069503726827,
      "loss": 0.1094,
      "step": 12925
    },
    {
      "epoch": 2.4671365974471327,
      "grad_norm": 0.3248635530471802,
      "learning_rate": 0.00017837803401923936,
      "loss": 0.0957,
      "step": 12950
    },
    {
      "epoch": 2.4718994094113165,
      "grad_norm": 0.30012914538383484,
      "learning_rate": 0.00017678537300121043,
      "loss": 0.1114,
      "step": 12975
    },
    {
      "epoch": 2.4766622213755003,
      "grad_norm": 0.2700045704841614,
      "learning_rate": 0.00017519271198318152,
      "loss": 0.1139,
      "step": 13000
    },
    {
      "epoch": 2.4814250333396837,
      "grad_norm": 0.37134066224098206,
      "learning_rate": 0.00017360005096515258,
      "loss": 0.1046,
      "step": 13025
    },
    {
      "epoch": 2.4861878453038675,
      "grad_norm": 0.47074049711227417,
      "learning_rate": 0.00017200738994712367,
      "loss": 0.1067,
      "step": 13050
    },
    {
      "epoch": 2.490950657268051,
      "grad_norm": 0.32839465141296387,
      "learning_rate": 0.00017041472892909474,
      "loss": 0.1085,
      "step": 13075
    },
    {
      "epoch": 2.4957134692322347,
      "grad_norm": 0.4108438789844513,
      "learning_rate": 0.0001688220679110658,
      "loss": 0.1047,
      "step": 13100
    },
    {
      "epoch": 2.5004762811964185,
      "grad_norm": 0.39525824785232544,
      "learning_rate": 0.0001672294068930369,
      "loss": 0.1076,
      "step": 13125
    },
    {
      "epoch": 2.505239093160602,
      "grad_norm": 0.3830445110797882,
      "learning_rate": 0.00016563674587500795,
      "loss": 0.105,
      "step": 13150
    },
    {
      "epoch": 2.5100019051247857,
      "grad_norm": 0.35366761684417725,
      "learning_rate": 0.00016404408485697905,
      "loss": 0.0947,
      "step": 13175
    },
    {
      "epoch": 2.514764717088969,
      "grad_norm": 0.46678322553634644,
      "learning_rate": 0.0001624514238389501,
      "loss": 0.1061,
      "step": 13200
    },
    {
      "epoch": 2.519527529053153,
      "grad_norm": 0.33284327387809753,
      "learning_rate": 0.0001608587628209212,
      "loss": 0.0945,
      "step": 13225
    },
    {
      "epoch": 2.5242903410173367,
      "grad_norm": 0.3331848084926605,
      "learning_rate": 0.00015926610180289226,
      "loss": 0.0964,
      "step": 13250
    },
    {
      "epoch": 2.52905315298152,
      "grad_norm": 0.2553977370262146,
      "learning_rate": 0.00015767344078486335,
      "loss": 0.1031,
      "step": 13275
    },
    {
      "epoch": 2.533815964945704,
      "grad_norm": 0.39041629433631897,
      "learning_rate": 0.00015608077976683445,
      "loss": 0.112,
      "step": 13300
    },
    {
      "epoch": 2.5385787769098878,
      "grad_norm": 0.23035740852355957,
      "learning_rate": 0.0001544881187488055,
      "loss": 0.1074,
      "step": 13325
    },
    {
      "epoch": 2.543341588874071,
      "grad_norm": 0.3145946264266968,
      "learning_rate": 0.0001528954577307766,
      "loss": 0.1011,
      "step": 13350
    },
    {
      "epoch": 2.548104400838255,
      "grad_norm": 0.31188085675239563,
      "learning_rate": 0.00015130279671274766,
      "loss": 0.0898,
      "step": 13375
    },
    {
      "epoch": 2.552867212802439,
      "grad_norm": 0.2576025128364563,
      "learning_rate": 0.00014971013569471876,
      "loss": 0.1108,
      "step": 13400
    },
    {
      "epoch": 2.557630024766622,
      "grad_norm": 0.2582634687423706,
      "learning_rate": 0.00014811747467668982,
      "loss": 0.1018,
      "step": 13425
    },
    {
      "epoch": 2.562392836730806,
      "grad_norm": 0.38238272070884705,
      "learning_rate": 0.00014652481365866088,
      "loss": 0.1191,
      "step": 13450
    },
    {
      "epoch": 2.5671556486949894,
      "grad_norm": 0.3352592885494232,
      "learning_rate": 0.00014493215264063197,
      "loss": 0.1025,
      "step": 13475
    },
    {
      "epoch": 2.571918460659173,
      "grad_norm": 0.40651237964630127,
      "learning_rate": 0.00014333949162260304,
      "loss": 0.1071,
      "step": 13500
    },
    {
      "epoch": 2.5766812726233566,
      "grad_norm": 0.3262072801589966,
      "learning_rate": 0.00014174683060457413,
      "loss": 0.0928,
      "step": 13525
    },
    {
      "epoch": 2.5814440845875404,
      "grad_norm": 0.42695146799087524,
      "learning_rate": 0.0001401541695865452,
      "loss": 0.1065,
      "step": 13550
    },
    {
      "epoch": 2.586206896551724,
      "grad_norm": 0.2249128222465515,
      "learning_rate": 0.00013856150856851628,
      "loss": 0.0994,
      "step": 13575
    },
    {
      "epoch": 2.5909697085159076,
      "grad_norm": 0.40320760011672974,
      "learning_rate": 0.00013696884755048735,
      "loss": 0.0984,
      "step": 13600
    },
    {
      "epoch": 2.5957325204800914,
      "grad_norm": 0.22227874398231506,
      "learning_rate": 0.0001353761865324584,
      "loss": 0.1087,
      "step": 13625
    },
    {
      "epoch": 2.600495332444275,
      "grad_norm": 0.32442301511764526,
      "learning_rate": 0.00013378352551442953,
      "loss": 0.0913,
      "step": 13650
    },
    {
      "epoch": 2.6052581444084586,
      "grad_norm": 0.5928651094436646,
      "learning_rate": 0.0001321908644964006,
      "loss": 0.1043,
      "step": 13675
    },
    {
      "epoch": 2.6100209563726424,
      "grad_norm": 0.35325875878334045,
      "learning_rate": 0.00013059820347837168,
      "loss": 0.102,
      "step": 13700
    },
    {
      "epoch": 2.6147837683368262,
      "grad_norm": 0.386927992105484,
      "learning_rate": 0.00012900554246034275,
      "loss": 0.1022,
      "step": 13725
    },
    {
      "epoch": 2.6195465803010096,
      "grad_norm": 0.2669632136821747,
      "learning_rate": 0.00012741288144231384,
      "loss": 0.0934,
      "step": 13750
    },
    {
      "epoch": 2.6243093922651934,
      "grad_norm": 0.23506927490234375,
      "learning_rate": 0.0001258202204242849,
      "loss": 0.0811,
      "step": 13775
    },
    {
      "epoch": 2.6290722042293773,
      "grad_norm": 0.34435567259788513,
      "learning_rate": 0.00012422755940625597,
      "loss": 0.093,
      "step": 13800
    },
    {
      "epoch": 2.6338350161935606,
      "grad_norm": 0.41047096252441406,
      "learning_rate": 0.00012263489838822706,
      "loss": 0.0955,
      "step": 13825
    },
    {
      "epoch": 2.6385978281577445,
      "grad_norm": 0.42583343386650085,
      "learning_rate": 0.00012104223737019813,
      "loss": 0.0985,
      "step": 13850
    },
    {
      "epoch": 2.643360640121928,
      "grad_norm": 0.41222646832466125,
      "learning_rate": 0.0001194495763521692,
      "loss": 0.0904,
      "step": 13875
    },
    {
      "epoch": 2.6481234520861117,
      "grad_norm": 0.3209845721721649,
      "learning_rate": 0.00011785691533414028,
      "loss": 0.1047,
      "step": 13900
    },
    {
      "epoch": 2.652886264050295,
      "grad_norm": 0.22219569981098175,
      "learning_rate": 0.00011626425431611135,
      "loss": 0.1049,
      "step": 13925
    },
    {
      "epoch": 2.657649076014479,
      "grad_norm": 0.4123961329460144,
      "learning_rate": 0.00011467159329808244,
      "loss": 0.0932,
      "step": 13950
    },
    {
      "epoch": 2.6624118879786627,
      "grad_norm": 0.4894864559173584,
      "learning_rate": 0.00011307893228005352,
      "loss": 0.1066,
      "step": 13975
    },
    {
      "epoch": 2.667174699942846,
      "grad_norm": 0.3813498020172119,
      "learning_rate": 0.0001114862712620246,
      "loss": 0.1084,
      "step": 14000
    },
    {
      "epoch": 2.67193751190703,
      "grad_norm": 0.3449605405330658,
      "learning_rate": 0.00010989361024399568,
      "loss": 0.0994,
      "step": 14025
    },
    {
      "epoch": 2.6767003238712137,
      "grad_norm": 0.290026992559433,
      "learning_rate": 0.00010830094922596674,
      "loss": 0.0984,
      "step": 14050
    },
    {
      "epoch": 2.681463135835397,
      "grad_norm": 0.29803481698036194,
      "learning_rate": 0.00010670828820793782,
      "loss": 0.0915,
      "step": 14075
    },
    {
      "epoch": 2.686225947799581,
      "grad_norm": 0.25901928544044495,
      "learning_rate": 0.0001051156271899089,
      "loss": 0.0993,
      "step": 14100
    },
    {
      "epoch": 2.6909887597637647,
      "grad_norm": 0.31960150599479675,
      "learning_rate": 0.00010352296617187998,
      "loss": 0.0881,
      "step": 14125
    },
    {
      "epoch": 2.695751571727948,
      "grad_norm": 0.31003937125205994,
      "learning_rate": 0.00010193030515385106,
      "loss": 0.1013,
      "step": 14150
    },
    {
      "epoch": 2.700514383692132,
      "grad_norm": 0.3384752571582794,
      "learning_rate": 0.00010033764413582214,
      "loss": 0.088,
      "step": 14175
    },
    {
      "epoch": 2.7052771956563157,
      "grad_norm": 0.31243056058883667,
      "learning_rate": 9.874498311779322e-05,
      "loss": 0.0959,
      "step": 14200
    },
    {
      "epoch": 2.710040007620499,
      "grad_norm": 0.35998955368995667,
      "learning_rate": 9.715232209976428e-05,
      "loss": 0.0976,
      "step": 14225
    },
    {
      "epoch": 2.714802819584683,
      "grad_norm": 0.2680616080760956,
      "learning_rate": 9.555966108173536e-05,
      "loss": 0.1026,
      "step": 14250
    },
    {
      "epoch": 2.7195656315488663,
      "grad_norm": 0.33488619327545166,
      "learning_rate": 9.396700006370644e-05,
      "loss": 0.0962,
      "step": 14275
    },
    {
      "epoch": 2.72432844351305,
      "grad_norm": 0.371455579996109,
      "learning_rate": 9.237433904567751e-05,
      "loss": 0.0937,
      "step": 14300
    },
    {
      "epoch": 2.7290912554772335,
      "grad_norm": 0.5803747773170471,
      "learning_rate": 9.07816780276486e-05,
      "loss": 0.1014,
      "step": 14325
    },
    {
      "epoch": 2.7338540674414173,
      "grad_norm": 0.31962546706199646,
      "learning_rate": 8.918901700961968e-05,
      "loss": 0.0999,
      "step": 14350
    },
    {
      "epoch": 2.738616879405601,
      "grad_norm": 0.5858180522918701,
      "learning_rate": 8.759635599159076e-05,
      "loss": 0.0889,
      "step": 14375
    },
    {
      "epoch": 2.7433796913697845,
      "grad_norm": 0.3328515887260437,
      "learning_rate": 8.600369497356184e-05,
      "loss": 0.0981,
      "step": 14400
    },
    {
      "epoch": 2.7481425033339684,
      "grad_norm": 0.28917640447616577,
      "learning_rate": 8.44110339555329e-05,
      "loss": 0.0934,
      "step": 14425
    },
    {
      "epoch": 2.752905315298152,
      "grad_norm": 0.3063790798187256,
      "learning_rate": 8.281837293750398e-05,
      "loss": 0.1071,
      "step": 14450
    },
    {
      "epoch": 2.7576681272623356,
      "grad_norm": 0.31669604778289795,
      "learning_rate": 8.122571191947505e-05,
      "loss": 0.0941,
      "step": 14475
    },
    {
      "epoch": 2.7624309392265194,
      "grad_norm": 0.46411213278770447,
      "learning_rate": 7.963305090144613e-05,
      "loss": 0.11,
      "step": 14500
    },
    {
      "epoch": 2.767193751190703,
      "grad_norm": 0.4713672697544098,
      "learning_rate": 7.804038988341722e-05,
      "loss": 0.093,
      "step": 14525
    },
    {
      "epoch": 2.7719565631548866,
      "grad_norm": 0.3244057297706604,
      "learning_rate": 7.64477288653883e-05,
      "loss": 0.0999,
      "step": 14550
    },
    {
      "epoch": 2.7767193751190704,
      "grad_norm": 0.37930551171302795,
      "learning_rate": 7.485506784735938e-05,
      "loss": 0.094,
      "step": 14575
    },
    {
      "epoch": 2.781482187083254,
      "grad_norm": 0.26087701320648193,
      "learning_rate": 7.326240682933044e-05,
      "loss": 0.1031,
      "step": 14600
    },
    {
      "epoch": 2.7862449990474376,
      "grad_norm": 0.3347434997558594,
      "learning_rate": 7.166974581130152e-05,
      "loss": 0.0888,
      "step": 14625
    },
    {
      "epoch": 2.791007811011621,
      "grad_norm": 0.5849473476409912,
      "learning_rate": 7.00770847932726e-05,
      "loss": 0.104,
      "step": 14650
    },
    {
      "epoch": 2.795770622975805,
      "grad_norm": 0.12303922325372696,
      "learning_rate": 6.848442377524367e-05,
      "loss": 0.0893,
      "step": 14675
    },
    {
      "epoch": 2.8005334349399886,
      "grad_norm": 0.3787361681461334,
      "learning_rate": 6.689176275721476e-05,
      "loss": 0.0927,
      "step": 14700
    },
    {
      "epoch": 2.805296246904172,
      "grad_norm": 0.4392329156398773,
      "learning_rate": 6.529910173918584e-05,
      "loss": 0.1023,
      "step": 14725
    },
    {
      "epoch": 2.810059058868356,
      "grad_norm": 0.31880706548690796,
      "learning_rate": 6.370644072115692e-05,
      "loss": 0.1072,
      "step": 14750
    },
    {
      "epoch": 2.8148218708325397,
      "grad_norm": 0.21010570228099823,
      "learning_rate": 6.211377970312798e-05,
      "loss": 0.0834,
      "step": 14775
    },
    {
      "epoch": 2.819584682796723,
      "grad_norm": 0.2546481788158417,
      "learning_rate": 6.052111868509907e-05,
      "loss": 0.0917,
      "step": 14800
    },
    {
      "epoch": 2.824347494760907,
      "grad_norm": 0.3683525025844574,
      "learning_rate": 5.892845766707014e-05,
      "loss": 0.0919,
      "step": 14825
    },
    {
      "epoch": 2.8291103067250907,
      "grad_norm": 0.32224327325820923,
      "learning_rate": 5.733579664904122e-05,
      "loss": 0.0867,
      "step": 14850
    },
    {
      "epoch": 2.833873118689274,
      "grad_norm": 0.3175424039363861,
      "learning_rate": 5.57431356310123e-05,
      "loss": 0.0858,
      "step": 14875
    },
    {
      "epoch": 2.838635930653458,
      "grad_norm": 0.3999274969100952,
      "learning_rate": 5.415047461298337e-05,
      "loss": 0.0957,
      "step": 14900
    },
    {
      "epoch": 2.8433987426176417,
      "grad_norm": 0.5427300930023193,
      "learning_rate": 5.255781359495445e-05,
      "loss": 0.095,
      "step": 14925
    },
    {
      "epoch": 2.848161554581825,
      "grad_norm": 0.3226345479488373,
      "learning_rate": 5.096515257692553e-05,
      "loss": 0.0924,
      "step": 14950
    },
    {
      "epoch": 2.852924366546009,
      "grad_norm": 0.4110727608203888,
      "learning_rate": 4.937249155889661e-05,
      "loss": 0.1141,
      "step": 14975
    },
    {
      "epoch": 2.8576871785101923,
      "grad_norm": 0.3313169777393341,
      "learning_rate": 4.777983054086768e-05,
      "loss": 0.0924,
      "step": 15000
    },
    {
      "epoch": 2.862449990474376,
      "grad_norm": 0.2505294680595398,
      "learning_rate": 4.6187169522838756e-05,
      "loss": 0.1023,
      "step": 15025
    },
    {
      "epoch": 2.8672128024385595,
      "grad_norm": 0.2947498559951782,
      "learning_rate": 4.459450850480984e-05,
      "loss": 0.1004,
      "step": 15050
    },
    {
      "epoch": 2.8719756144027433,
      "grad_norm": 0.5288525223731995,
      "learning_rate": 4.300184748678092e-05,
      "loss": 0.1045,
      "step": 15075
    },
    {
      "epoch": 2.876738426366927,
      "grad_norm": 0.157892107963562,
      "learning_rate": 4.140918646875199e-05,
      "loss": 0.1023,
      "step": 15100
    },
    {
      "epoch": 2.8815012383311105,
      "grad_norm": 0.25126564502716064,
      "learning_rate": 3.9816525450723066e-05,
      "loss": 0.0785,
      "step": 15125
    },
    {
      "epoch": 2.8862640502952943,
      "grad_norm": 0.19405515491962433,
      "learning_rate": 3.822386443269415e-05,
      "loss": 0.0843,
      "step": 15150
    },
    {
      "epoch": 2.891026862259478,
      "grad_norm": 0.29403430223464966,
      "learning_rate": 3.663120341466522e-05,
      "loss": 0.094,
      "step": 15175
    },
    {
      "epoch": 2.8957896742236615,
      "grad_norm": 0.3394172787666321,
      "learning_rate": 3.50385423966363e-05,
      "loss": 0.0962,
      "step": 15200
    },
    {
      "epoch": 2.9005524861878453,
      "grad_norm": 0.40449538826942444,
      "learning_rate": 3.344588137860738e-05,
      "loss": 0.0988,
      "step": 15225
    },
    {
      "epoch": 2.905315298152029,
      "grad_norm": 0.254518061876297,
      "learning_rate": 3.185322036057846e-05,
      "loss": 0.0882,
      "step": 15250
    },
    {
      "epoch": 2.9100781101162125,
      "grad_norm": 0.4333747923374176,
      "learning_rate": 3.0260559342549533e-05,
      "loss": 0.098,
      "step": 15275
    },
    {
      "epoch": 2.9148409220803964,
      "grad_norm": 0.32788512110710144,
      "learning_rate": 2.866789832452061e-05,
      "loss": 0.0986,
      "step": 15300
    },
    {
      "epoch": 2.91960373404458,
      "grad_norm": 0.44069311022758484,
      "learning_rate": 2.7075237306491685e-05,
      "loss": 0.0985,
      "step": 15325
    },
    {
      "epoch": 2.9243665460087636,
      "grad_norm": 0.3940051198005676,
      "learning_rate": 2.5482576288462766e-05,
      "loss": 0.0993,
      "step": 15350
    },
    {
      "epoch": 2.9291293579729474,
      "grad_norm": 0.3258838355541229,
      "learning_rate": 2.388991527043384e-05,
      "loss": 0.1054,
      "step": 15375
    },
    {
      "epoch": 2.9338921699371308,
      "grad_norm": 0.22694779932498932,
      "learning_rate": 2.229725425240492e-05,
      "loss": 0.0824,
      "step": 15400
    },
    {
      "epoch": 2.9386549819013146,
      "grad_norm": 0.32100552320480347,
      "learning_rate": 2.0704593234375994e-05,
      "loss": 0.0905,
      "step": 15425
    },
    {
      "epoch": 2.943417793865498,
      "grad_norm": 0.2338995784521103,
      "learning_rate": 1.9111932216347075e-05,
      "loss": 0.0914,
      "step": 15450
    },
    {
      "epoch": 2.9481806058296818,
      "grad_norm": 0.40045166015625,
      "learning_rate": 1.751927119831815e-05,
      "loss": 0.085,
      "step": 15475
    },
    {
      "epoch": 2.9529434177938656,
      "grad_norm": 0.3664804995059967,
      "learning_rate": 1.592661018028923e-05,
      "loss": 0.1022,
      "step": 15500
    },
    {
      "epoch": 2.3006816834617663,
      "grad_norm": 0.3898058831691742,
      "learning_rate": 0.0002338318312370011,
      "loss": 0.1305,
      "step": 15525
    },
    {
      "epoch": 2.30438648488441,
      "grad_norm": 0.3920365273952484,
      "learning_rate": 0.0002325938397543825,
      "loss": 0.1268,
      "step": 15550
    },
    {
      "epoch": 2.3080912863070537,
      "grad_norm": 0.38450703024864197,
      "learning_rate": 0.0002313558482717639,
      "loss": 0.1268,
      "step": 15575
    },
    {
      "epoch": 2.3117960877296975,
      "grad_norm": 0.41167116165161133,
      "learning_rate": 0.00023011785678914528,
      "loss": 0.1347,
      "step": 15600
    },
    {
      "epoch": 2.315500889152341,
      "grad_norm": 0.3430323600769043,
      "learning_rate": 0.00022887986530652668,
      "loss": 0.1264,
      "step": 15625
    },
    {
      "epoch": 2.319205690574985,
      "grad_norm": 0.33534491062164307,
      "learning_rate": 0.00022764187382390811,
      "loss": 0.1202,
      "step": 15650
    },
    {
      "epoch": 2.322910491997629,
      "grad_norm": 0.3046797513961792,
      "learning_rate": 0.0002264038823412895,
      "loss": 0.1334,
      "step": 15675
    },
    {
      "epoch": 2.326615293420273,
      "grad_norm": 0.8269021511077881,
      "learning_rate": 0.0002251658908586709,
      "loss": 0.1518,
      "step": 15700
    },
    {
      "epoch": 2.3303200948429166,
      "grad_norm": 0.5091423392295837,
      "learning_rate": 0.0002239278993760523,
      "loss": 0.1426,
      "step": 15725
    },
    {
      "epoch": 2.3340248962655603,
      "grad_norm": 0.35139933228492737,
      "learning_rate": 0.00022268990789343367,
      "loss": 0.1365,
      "step": 15750
    },
    {
      "epoch": 2.337729697688204,
      "grad_norm": 0.2573777139186859,
      "learning_rate": 0.0002214519164108151,
      "loss": 0.1537,
      "step": 15775
    },
    {
      "epoch": 2.3414344991108478,
      "grad_norm": 0.3172297775745392,
      "learning_rate": 0.0002202139249281965,
      "loss": 0.1384,
      "step": 15800
    },
    {
      "epoch": 2.3451393005334915,
      "grad_norm": 0.3905620276927948,
      "learning_rate": 0.0002189759334455779,
      "loss": 0.1269,
      "step": 15825
    },
    {
      "epoch": 2.3488441019561352,
      "grad_norm": 0.7219096422195435,
      "learning_rate": 0.00021773794196295929,
      "loss": 0.1456,
      "step": 15850
    },
    {
      "epoch": 2.352548903378779,
      "grad_norm": 0.3133063018321991,
      "learning_rate": 0.00021649995048034072,
      "loss": 0.1513,
      "step": 15875
    },
    {
      "epoch": 2.3562537048014227,
      "grad_norm": 0.4551685154438019,
      "learning_rate": 0.00021526195899772212,
      "loss": 0.1179,
      "step": 15900
    },
    {
      "epoch": 2.3599585062240664,
      "grad_norm": 0.5355347394943237,
      "learning_rate": 0.0002140239675151035,
      "loss": 0.1411,
      "step": 15925
    },
    {
      "epoch": 2.36366330764671,
      "grad_norm": 0.2276145964860916,
      "learning_rate": 0.0002127859760324849,
      "loss": 0.1318,
      "step": 15950
    },
    {
      "epoch": 2.367368109069354,
      "grad_norm": 0.5001741051673889,
      "learning_rate": 0.0002115479845498663,
      "loss": 0.1472,
      "step": 15975
    },
    {
      "epoch": 2.3710729104919976,
      "grad_norm": 0.36345943808555603,
      "learning_rate": 0.0002103099930672477,
      "loss": 0.1219,
      "step": 16000
    },
    {
      "epoch": 2.3747777119146414,
      "grad_norm": 0.33696407079696655,
      "learning_rate": 0.0002090720015846291,
      "loss": 0.1343,
      "step": 16025
    },
    {
      "epoch": 2.378482513337285,
      "grad_norm": 0.5222005248069763,
      "learning_rate": 0.0002078340101020105,
      "loss": 0.1222,
      "step": 16050
    },
    {
      "epoch": 2.382187314759929,
      "grad_norm": 0.2918776273727417,
      "learning_rate": 0.0002065960186193919,
      "loss": 0.1166,
      "step": 16075
    },
    {
      "epoch": 2.3858921161825726,
      "grad_norm": 0.44915392994880676,
      "learning_rate": 0.0002053580271367733,
      "loss": 0.1441,
      "step": 16100
    },
    {
      "epoch": 2.3895969176052163,
      "grad_norm": 0.4898615777492523,
      "learning_rate": 0.00020412003565415472,
      "loss": 0.1302,
      "step": 16125
    },
    {
      "epoch": 2.39330171902786,
      "grad_norm": 0.2911985516548157,
      "learning_rate": 0.0002028820441715361,
      "loss": 0.1232,
      "step": 16150
    },
    {
      "epoch": 2.3970065204505038,
      "grad_norm": 0.369361013174057,
      "learning_rate": 0.0002016440526889175,
      "loss": 0.1501,
      "step": 16175
    },
    {
      "epoch": 2.4007113218731475,
      "grad_norm": 0.33158648014068604,
      "learning_rate": 0.0002004060612062989,
      "loss": 0.1374,
      "step": 16200
    },
    {
      "epoch": 2.4044161232957912,
      "grad_norm": 0.2889860272407532,
      "learning_rate": 0.0001991680697236803,
      "loss": 0.1238,
      "step": 16225
    },
    {
      "epoch": 2.408120924718435,
      "grad_norm": 0.2988782227039337,
      "learning_rate": 0.0001979300782410617,
      "loss": 0.1219,
      "step": 16250
    },
    {
      "epoch": 2.4118257261410787,
      "grad_norm": 0.5262881517410278,
      "learning_rate": 0.00019669208675844311,
      "loss": 0.1436,
      "step": 16275
    },
    {
      "epoch": 2.4155305275637224,
      "grad_norm": 0.4014163911342621,
      "learning_rate": 0.0001954540952758245,
      "loss": 0.1391,
      "step": 16300
    },
    {
      "epoch": 2.419235328986366,
      "grad_norm": 0.34578853845596313,
      "learning_rate": 0.0001942161037932059,
      "loss": 0.1431,
      "step": 16325
    },
    {
      "epoch": 2.42294013040901,
      "grad_norm": 0.2729792296886444,
      "learning_rate": 0.00019297811231058732,
      "loss": 0.1248,
      "step": 16350
    },
    {
      "epoch": 2.4266449318316536,
      "grad_norm": 0.3028084635734558,
      "learning_rate": 0.0001917401208279687,
      "loss": 0.125,
      "step": 16375
    },
    {
      "epoch": 2.430349733254298,
      "grad_norm": 0.26355165243148804,
      "learning_rate": 0.0001905021293453501,
      "loss": 0.1347,
      "step": 16400
    },
    {
      "epoch": 2.4340545346769416,
      "grad_norm": 0.3254702389240265,
      "learning_rate": 0.0001892641378627315,
      "loss": 0.1323,
      "step": 16425
    },
    {
      "epoch": 2.4377593360995853,
      "grad_norm": 0.3672489821910858,
      "learning_rate": 0.0001880261463801129,
      "loss": 0.1259,
      "step": 16450
    },
    {
      "epoch": 2.441464137522229,
      "grad_norm": 0.48000621795654297,
      "learning_rate": 0.00018678815489749431,
      "loss": 0.1308,
      "step": 16475
    },
    {
      "epoch": 2.4451689389448727,
      "grad_norm": 0.35778525471687317,
      "learning_rate": 0.00018555016341487572,
      "loss": 0.1379,
      "step": 16500
    },
    {
      "epoch": 2.4488737403675165,
      "grad_norm": 0.36433541774749756,
      "learning_rate": 0.0001843121719322571,
      "loss": 0.1189,
      "step": 16525
    },
    {
      "epoch": 2.45257854179016,
      "grad_norm": 0.3916415572166443,
      "learning_rate": 0.0001830741804496385,
      "loss": 0.1308,
      "step": 16550
    },
    {
      "epoch": 2.456283343212804,
      "grad_norm": 0.24967683851718903,
      "learning_rate": 0.00018183618896701993,
      "loss": 0.1359,
      "step": 16575
    },
    {
      "epoch": 2.4599881446354477,
      "grad_norm": 0.38144341111183167,
      "learning_rate": 0.0001805981974844013,
      "loss": 0.1442,
      "step": 16600
    },
    {
      "epoch": 2.4636929460580914,
      "grad_norm": 0.3191845715045929,
      "learning_rate": 0.0001793602060017827,
      "loss": 0.1337,
      "step": 16625
    },
    {
      "epoch": 2.467397747480735,
      "grad_norm": 0.40418508648872375,
      "learning_rate": 0.0001781222145191641,
      "loss": 0.1328,
      "step": 16650
    },
    {
      "epoch": 2.471102548903379,
      "grad_norm": 0.25813913345336914,
      "learning_rate": 0.00017688422303654549,
      "loss": 0.1325,
      "step": 16675
    },
    {
      "epoch": 2.4748073503260226,
      "grad_norm": 0.3696320056915283,
      "learning_rate": 0.00017564623155392692,
      "loss": 0.1185,
      "step": 16700
    },
    {
      "epoch": 2.4785121517486663,
      "grad_norm": 0.35358208417892456,
      "learning_rate": 0.00017440824007130832,
      "loss": 0.1231,
      "step": 16725
    },
    {
      "epoch": 2.48221695317131,
      "grad_norm": 1.0227328538894653,
      "learning_rate": 0.00017317024858868972,
      "loss": 0.1397,
      "step": 16750
    },
    {
      "epoch": 2.485921754593954,
      "grad_norm": 0.46978893876075745,
      "learning_rate": 0.0001719322571060711,
      "loss": 0.1234,
      "step": 16775
    },
    {
      "epoch": 2.4896265560165975,
      "grad_norm": 0.30264464020729065,
      "learning_rate": 0.00017069426562345253,
      "loss": 0.1355,
      "step": 16800
    },
    {
      "epoch": 2.4933313574392413,
      "grad_norm": 0.3746185302734375,
      "learning_rate": 0.00016945627414083393,
      "loss": 0.1294,
      "step": 16825
    },
    {
      "epoch": 2.497036158861885,
      "grad_norm": 0.4090883433818817,
      "learning_rate": 0.0001682182826582153,
      "loss": 0.1295,
      "step": 16850
    },
    {
      "epoch": 2.5007409602845287,
      "grad_norm": 0.3576558232307434,
      "learning_rate": 0.0001669802911755967,
      "loss": 0.1354,
      "step": 16875
    },
    {
      "epoch": 2.5044457617071725,
      "grad_norm": 0.4292697310447693,
      "learning_rate": 0.00016574229969297812,
      "loss": 0.1321,
      "step": 16900
    },
    {
      "epoch": 2.508150563129816,
      "grad_norm": 0.39548802375793457,
      "learning_rate": 0.00016450430821035952,
      "loss": 0.1324,
      "step": 16925
    },
    {
      "epoch": 2.51185536455246,
      "grad_norm": 0.4139944016933441,
      "learning_rate": 0.00016326631672774092,
      "loss": 0.1289,
      "step": 16950
    },
    {
      "epoch": 2.5155601659751037,
      "grad_norm": 0.31051814556121826,
      "learning_rate": 0.00016202832524512233,
      "loss": 0.1368,
      "step": 16975
    },
    {
      "epoch": 2.5192649673977474,
      "grad_norm": 0.40797755122184753,
      "learning_rate": 0.0001607903337625037,
      "loss": 0.1359,
      "step": 17000
    },
    {
      "epoch": 2.522969768820391,
      "grad_norm": 0.3168090581893921,
      "learning_rate": 0.0001595523422798851,
      "loss": 0.1341,
      "step": 17025
    },
    {
      "epoch": 2.526674570243035,
      "grad_norm": 0.307252436876297,
      "learning_rate": 0.00015831435079726654,
      "loss": 0.1422,
      "step": 17050
    },
    {
      "epoch": 2.5303793716656786,
      "grad_norm": 0.2798117995262146,
      "learning_rate": 0.0001570763593146479,
      "loss": 0.1159,
      "step": 17075
    },
    {
      "epoch": 2.5340841730883223,
      "grad_norm": 0.43331825733184814,
      "learning_rate": 0.00015583836783202932,
      "loss": 0.1339,
      "step": 17100
    },
    {
      "epoch": 2.537788974510966,
      "grad_norm": 0.2980557084083557,
      "learning_rate": 0.00015460037634941072,
      "loss": 0.127,
      "step": 17125
    },
    {
      "epoch": 2.54149377593361,
      "grad_norm": 0.3416631817817688,
      "learning_rate": 0.00015336238486679212,
      "loss": 0.138,
      "step": 17150
    },
    {
      "epoch": 2.5451985773562535,
      "grad_norm": 0.35435986518859863,
      "learning_rate": 0.00015212439338417353,
      "loss": 0.1316,
      "step": 17175
    },
    {
      "epoch": 2.5489033787788973,
      "grad_norm": 0.25167208909988403,
      "learning_rate": 0.00015088640190155493,
      "loss": 0.124,
      "step": 17200
    },
    {
      "epoch": 2.552608180201541,
      "grad_norm": 0.44606733322143555,
      "learning_rate": 0.0001496484104189363,
      "loss": 0.1445,
      "step": 17225
    },
    {
      "epoch": 2.5563129816241847,
      "grad_norm": 0.43036648631095886,
      "learning_rate": 0.0001484104189363177,
      "loss": 0.1353,
      "step": 17250
    },
    {
      "epoch": 2.5600177830468285,
      "grad_norm": 0.21026889979839325,
      "learning_rate": 0.00014717242745369914,
      "loss": 0.1394,
      "step": 17275
    },
    {
      "epoch": 2.563722584469472,
      "grad_norm": 0.42296266555786133,
      "learning_rate": 0.00014593443597108051,
      "loss": 0.124,
      "step": 17300
    },
    {
      "epoch": 2.567427385892116,
      "grad_norm": 0.38212519884109497,
      "learning_rate": 0.00014469644448846192,
      "loss": 0.1331,
      "step": 17325
    },
    {
      "epoch": 2.5711321873147597,
      "grad_norm": 0.34892308712005615,
      "learning_rate": 0.00014345845300584332,
      "loss": 0.1347,
      "step": 17350
    },
    {
      "epoch": 2.5748369887374034,
      "grad_norm": 0.30408933758735657,
      "learning_rate": 0.00014222046152322472,
      "loss": 0.1292,
      "step": 17375
    },
    {
      "epoch": 2.5785417901600476,
      "grad_norm": 0.2818223536014557,
      "learning_rate": 0.00014098247004060613,
      "loss": 0.1371,
      "step": 17400
    },
    {
      "epoch": 2.5822465915826913,
      "grad_norm": 0.41565579175949097,
      "learning_rate": 0.00013974447855798753,
      "loss": 0.1321,
      "step": 17425
    },
    {
      "epoch": 2.585951393005335,
      "grad_norm": 0.4051836431026459,
      "learning_rate": 0.0001385064870753689,
      "loss": 0.1286,
      "step": 17450
    },
    {
      "epoch": 2.589656194427979,
      "grad_norm": 0.4223898947238922,
      "learning_rate": 0.0001372684955927503,
      "loss": 0.1204,
      "step": 17475
    },
    {
      "epoch": 2.5933609958506225,
      "grad_norm": 0.503333330154419,
      "learning_rate": 0.00013603050411013174,
      "loss": 0.139,
      "step": 17500
    },
    {
      "epoch": 2.5970657972732663,
      "grad_norm": 0.33855271339416504,
      "learning_rate": 0.00013479251262751312,
      "loss": 0.126,
      "step": 17525
    },
    {
      "epoch": 2.60077059869591,
      "grad_norm": 0.2660727798938751,
      "learning_rate": 0.00013355452114489452,
      "loss": 0.1305,
      "step": 17550
    },
    {
      "epoch": 2.6044754001185537,
      "grad_norm": 0.15822559595108032,
      "learning_rate": 0.00013231652966227592,
      "loss": 0.1234,
      "step": 17575
    },
    {
      "epoch": 2.6081802015411975,
      "grad_norm": 0.4902530014514923,
      "learning_rate": 0.00013107853817965733,
      "loss": 0.1227,
      "step": 17600
    },
    {
      "epoch": 2.611885002963841,
      "grad_norm": 0.30706652998924255,
      "learning_rate": 0.00012984054669703873,
      "loss": 0.1282,
      "step": 17625
    },
    {
      "epoch": 2.615589804386485,
      "grad_norm": 0.1629856377840042,
      "learning_rate": 0.00012860255521442013,
      "loss": 0.1203,
      "step": 17650
    },
    {
      "epoch": 2.6192946058091287,
      "grad_norm": 0.46989428997039795,
      "learning_rate": 0.00012736456373180154,
      "loss": 0.1335,
      "step": 17675
    },
    {
      "epoch": 2.6229994072317724,
      "grad_norm": 0.3835347294807434,
      "learning_rate": 0.0001261265722491829,
      "loss": 0.1311,
      "step": 17700
    },
    {
      "epoch": 2.626704208654416,
      "grad_norm": 0.3577720820903778,
      "learning_rate": 0.00012488858076656432,
      "loss": 0.1228,
      "step": 17725
    },
    {
      "epoch": 2.63040901007706,
      "grad_norm": 0.3725482225418091,
      "learning_rate": 0.00012365058928394575,
      "loss": 0.1385,
      "step": 17750
    },
    {
      "epoch": 2.6341138114997036,
      "grad_norm": 0.24986691772937775,
      "learning_rate": 0.00012241259780132712,
      "loss": 0.1324,
      "step": 17775
    },
    {
      "epoch": 2.6378186129223473,
      "grad_norm": 0.293917179107666,
      "learning_rate": 0.00012117460631870853,
      "loss": 0.1226,
      "step": 17800
    },
    {
      "epoch": 2.641523414344991,
      "grad_norm": 0.32792189717292786,
      "learning_rate": 0.00011993661483608993,
      "loss": 0.1378,
      "step": 17825
    },
    {
      "epoch": 2.645228215767635,
      "grad_norm": 0.397241473197937,
      "learning_rate": 0.00011869862335347133,
      "loss": 0.112,
      "step": 17850
    },
    {
      "epoch": 2.6489330171902785,
      "grad_norm": 0.35217371582984924,
      "learning_rate": 0.00011746063187085274,
      "loss": 0.1253,
      "step": 17875
    },
    {
      "epoch": 2.6526378186129222,
      "grad_norm": 0.3015689551830292,
      "learning_rate": 0.00011622264038823413,
      "loss": 0.1185,
      "step": 17900
    },
    {
      "epoch": 2.656342620035566,
      "grad_norm": 0.17752724885940552,
      "learning_rate": 0.00011498464890561554,
      "loss": 0.1481,
      "step": 17925
    },
    {
      "epoch": 2.6600474214582097,
      "grad_norm": 0.5124810338020325,
      "learning_rate": 0.00011374665742299693,
      "loss": 0.1209,
      "step": 17950
    },
    {
      "epoch": 2.6637522228808534,
      "grad_norm": 0.26260608434677124,
      "learning_rate": 0.00011250866594037832,
      "loss": 0.1141,
      "step": 17975
    },
    {
      "epoch": 2.667457024303497,
      "grad_norm": 0.34906473755836487,
      "learning_rate": 0.00011127067445775974,
      "loss": 0.1333,
      "step": 18000
    },
    {
      "epoch": 2.671161825726141,
      "grad_norm": 0.4824296832084656,
      "learning_rate": 0.00011003268297514113,
      "loss": 0.1297,
      "step": 18025
    },
    {
      "epoch": 2.674866627148785,
      "grad_norm": 0.24359333515167236,
      "learning_rate": 0.00010879469149252253,
      "loss": 0.1299,
      "step": 18050
    },
    {
      "epoch": 2.678571428571429,
      "grad_norm": 0.4227740168571472,
      "learning_rate": 0.00010755670000990394,
      "loss": 0.122,
      "step": 18075
    },
    {
      "epoch": 2.6822762299940726,
      "grad_norm": 0.34577974677085876,
      "learning_rate": 0.00010631870852728534,
      "loss": 0.1249,
      "step": 18100
    },
    {
      "epoch": 2.6859810314167163,
      "grad_norm": 0.3684179484844208,
      "learning_rate": 0.00010508071704466673,
      "loss": 0.1283,
      "step": 18125
    },
    {
      "epoch": 2.68968583283936,
      "grad_norm": 0.25428470969200134,
      "learning_rate": 0.00010384272556204813,
      "loss": 0.1097,
      "step": 18150
    },
    {
      "epoch": 2.6933906342620038,
      "grad_norm": 0.4077584743499756,
      "learning_rate": 0.00010260473407942954,
      "loss": 0.1282,
      "step": 18175
    },
    {
      "epoch": 2.6970954356846475,
      "grad_norm": 0.2899472117424011,
      "learning_rate": 0.00010136674259681093,
      "loss": 0.1094,
      "step": 18200
    },
    {
      "epoch": 2.7008002371072912,
      "grad_norm": 0.20521576702594757,
      "learning_rate": 0.00010012875111419234,
      "loss": 0.1168,
      "step": 18225
    },
    {
      "epoch": 2.704505038529935,
      "grad_norm": 0.3484284281730652,
      "learning_rate": 9.889075963157373e-05,
      "loss": 0.1161,
      "step": 18250
    },
    {
      "epoch": 2.7082098399525787,
      "grad_norm": 0.34171879291534424,
      "learning_rate": 9.765276814895515e-05,
      "loss": 0.1201,
      "step": 18275
    },
    {
      "epoch": 2.7119146413752224,
      "grad_norm": 0.25110581517219543,
      "learning_rate": 9.641477666633654e-05,
      "loss": 0.1187,
      "step": 18300
    },
    {
      "epoch": 2.715619442797866,
      "grad_norm": 0.3154144883155823,
      "learning_rate": 9.517678518371793e-05,
      "loss": 0.123,
      "step": 18325
    },
    {
      "epoch": 2.71932424422051,
      "grad_norm": 0.36302775144577026,
      "learning_rate": 9.393879370109935e-05,
      "loss": 0.1187,
      "step": 18350
    },
    {
      "epoch": 2.7230290456431536,
      "grad_norm": 0.3863254189491272,
      "learning_rate": 9.270080221848073e-05,
      "loss": 0.1288,
      "step": 18375
    },
    {
      "epoch": 2.7267338470657974,
      "grad_norm": 0.27594178915023804,
      "learning_rate": 9.146281073586214e-05,
      "loss": 0.1211,
      "step": 18400
    },
    {
      "epoch": 2.730438648488441,
      "grad_norm": 0.2943366765975952,
      "learning_rate": 9.022481925324354e-05,
      "loss": 0.1178,
      "step": 18425
    },
    {
      "epoch": 2.734143449911085,
      "grad_norm": 0.30518394708633423,
      "learning_rate": 8.898682777062494e-05,
      "loss": 0.1278,
      "step": 18450
    },
    {
      "epoch": 2.7378482513337286,
      "grad_norm": 0.3021693229675293,
      "learning_rate": 8.774883628800633e-05,
      "loss": 0.1299,
      "step": 18475
    },
    {
      "epoch": 2.7415530527563723,
      "grad_norm": 0.4038892984390259,
      "learning_rate": 8.651084480538774e-05,
      "loss": 0.1282,
      "step": 18500
    },
    {
      "epoch": 2.745257854179016,
      "grad_norm": 0.38556236028671265,
      "learning_rate": 8.527285332276914e-05,
      "loss": 0.1181,
      "step": 18525
    },
    {
      "epoch": 2.7489626556016598,
      "grad_norm": 0.22745442390441895,
      "learning_rate": 8.403486184015053e-05,
      "loss": 0.1141,
      "step": 18550
    },
    {
      "epoch": 2.7526674570243035,
      "grad_norm": 0.4119665026664734,
      "learning_rate": 8.279687035753195e-05,
      "loss": 0.1232,
      "step": 18575
    },
    {
      "epoch": 2.756372258446947,
      "grad_norm": 0.5654836297035217,
      "learning_rate": 8.160839853421809e-05,
      "loss": 0.1352,
      "step": 18600
    },
    {
      "epoch": 2.760077059869591,
      "grad_norm": 0.2899385094642639,
      "learning_rate": 8.037040705159948e-05,
      "loss": 0.118,
      "step": 18625
    },
    {
      "epoch": 2.7637818612922347,
      "grad_norm": 0.3014053702354431,
      "learning_rate": 7.91324155689809e-05,
      "loss": 0.1196,
      "step": 18650
    },
    {
      "epoch": 2.7674866627148784,
      "grad_norm": 0.2645430862903595,
      "learning_rate": 7.789442408636228e-05,
      "loss": 0.1206,
      "step": 18675
    },
    {
      "epoch": 2.771191464137522,
      "grad_norm": 0.3297572731971741,
      "learning_rate": 7.665643260374369e-05,
      "loss": 0.1113,
      "step": 18700
    },
    {
      "epoch": 2.774896265560166,
      "grad_norm": 0.2531875967979431,
      "learning_rate": 7.541844112112509e-05,
      "loss": 0.1197,
      "step": 18725
    },
    {
      "epoch": 2.7786010669828096,
      "grad_norm": 0.37726306915283203,
      "learning_rate": 7.418044963850649e-05,
      "loss": 0.1328,
      "step": 18750
    },
    {
      "epoch": 2.7823058684054534,
      "grad_norm": 0.2992542088031769,
      "learning_rate": 7.294245815588788e-05,
      "loss": 0.1183,
      "step": 18775
    },
    {
      "epoch": 2.786010669828097,
      "grad_norm": 0.6621007323265076,
      "learning_rate": 7.170446667326929e-05,
      "loss": 0.1051,
      "step": 18800
    },
    {
      "epoch": 2.789715471250741,
      "grad_norm": 0.3017505407333374,
      "learning_rate": 7.046647519065069e-05,
      "loss": 0.1122,
      "step": 18825
    },
    {
      "epoch": 2.7934202726733846,
      "grad_norm": 0.4510633051395416,
      "learning_rate": 6.922848370803209e-05,
      "loss": 0.1184,
      "step": 18850
    },
    {
      "epoch": 2.7971250740960283,
      "grad_norm": 0.397089421749115,
      "learning_rate": 6.79904922254135e-05,
      "loss": 0.1164,
      "step": 18875
    },
    {
      "epoch": 2.800829875518672,
      "grad_norm": 0.2965546250343323,
      "learning_rate": 6.675250074279489e-05,
      "loss": 0.1183,
      "step": 18900
    },
    {
      "epoch": 2.8045346769413158,
      "grad_norm": 0.38130712509155273,
      "learning_rate": 6.55145092601763e-05,
      "loss": 0.134,
      "step": 18925
    },
    {
      "epoch": 2.8082394783639595,
      "grad_norm": 0.44307535886764526,
      "learning_rate": 6.427651777755769e-05,
      "loss": 0.1174,
      "step": 18950
    },
    {
      "epoch": 2.811944279786603,
      "grad_norm": 0.2674178183078766,
      "learning_rate": 6.303852629493908e-05,
      "loss": 0.1177,
      "step": 18975
    },
    {
      "epoch": 2.815649081209247,
      "grad_norm": 0.35872629284858704,
      "learning_rate": 6.18005348123205e-05,
      "loss": 0.137,
      "step": 19000
    },
    {
      "epoch": 2.8193538826318907,
      "grad_norm": 0.320158451795578,
      "learning_rate": 6.0562543329701895e-05,
      "loss": 0.1229,
      "step": 19025
    },
    {
      "epoch": 2.8230586840545344,
      "grad_norm": 0.48922237753868103,
      "learning_rate": 5.932455184708329e-05,
      "loss": 0.1105,
      "step": 19050
    },
    {
      "epoch": 2.826763485477178,
      "grad_norm": 0.277859091758728,
      "learning_rate": 5.808656036446469e-05,
      "loss": 0.1172,
      "step": 19075
    },
    {
      "epoch": 2.8304682868998223,
      "grad_norm": 0.3332785367965698,
      "learning_rate": 5.684856888184609e-05,
      "loss": 0.1136,
      "step": 19100
    },
    {
      "epoch": 2.834173088322466,
      "grad_norm": 0.3094378113746643,
      "learning_rate": 5.5610577399227495e-05,
      "loss": 0.1158,
      "step": 19125
    },
    {
      "epoch": 2.83787788974511,
      "grad_norm": 0.27770981192588806,
      "learning_rate": 5.43725859166089e-05,
      "loss": 0.1245,
      "step": 19150
    },
    {
      "epoch": 2.8415826911677535,
      "grad_norm": 0.560103178024292,
      "learning_rate": 5.3134594433990295e-05,
      "loss": 0.1242,
      "step": 19175
    },
    {
      "epoch": 2.8452874925903973,
      "grad_norm": 0.27342501282691956,
      "learning_rate": 5.18966029513717e-05,
      "loss": 0.1042,
      "step": 19200
    },
    {
      "epoch": 2.848992294013041,
      "grad_norm": 0.16005484759807587,
      "learning_rate": 5.06586114687531e-05,
      "loss": 0.1106,
      "step": 19225
    },
    {
      "epoch": 2.8526970954356847,
      "grad_norm": 0.45349451899528503,
      "learning_rate": 4.942061998613449e-05,
      "loss": 0.1201,
      "step": 19250
    },
    {
      "epoch": 2.8564018968583285,
      "grad_norm": 0.2830646336078644,
      "learning_rate": 4.8182628503515895e-05,
      "loss": 0.1142,
      "step": 19275
    },
    {
      "epoch": 2.860106698280972,
      "grad_norm": 0.44501176476478577,
      "learning_rate": 4.69446370208973e-05,
      "loss": 0.1235,
      "step": 19300
    },
    {
      "epoch": 2.863811499703616,
      "grad_norm": 0.2717507779598236,
      "learning_rate": 4.5706645538278694e-05,
      "loss": 0.1212,
      "step": 19325
    },
    {
      "epoch": 2.8675163011262597,
      "grad_norm": 0.4947645366191864,
      "learning_rate": 4.44686540556601e-05,
      "loss": 0.1155,
      "step": 19350
    },
    {
      "epoch": 2.8712211025489034,
      "grad_norm": 0.2660922408103943,
      "learning_rate": 4.32306625730415e-05,
      "loss": 0.115,
      "step": 19375
    },
    {
      "epoch": 2.874925903971547,
      "grad_norm": 0.4379338026046753,
      "learning_rate": 4.1992671090422904e-05,
      "loss": 0.1143,
      "step": 19400
    },
    {
      "epoch": 2.878630705394191,
      "grad_norm": 0.26960986852645874,
      "learning_rate": 4.0754679607804294e-05,
      "loss": 0.1168,
      "step": 19425
    },
    {
      "epoch": 2.8823355068168346,
      "grad_norm": 0.345935583114624,
      "learning_rate": 3.95166881251857e-05,
      "loss": 0.1287,
      "step": 19450
    },
    {
      "epoch": 2.8860403082394783,
      "grad_norm": 0.31554147601127625,
      "learning_rate": 3.82786966425671e-05,
      "loss": 0.1153,
      "step": 19475
    },
    {
      "epoch": 2.889745109662122,
      "grad_norm": 0.2527219355106354,
      "learning_rate": 3.70407051599485e-05,
      "loss": 0.1011,
      "step": 19500
    },
    {
      "epoch": 2.893449911084766,
      "grad_norm": 0.5218963027000427,
      "learning_rate": 3.58027136773299e-05,
      "loss": 0.1186,
      "step": 19525
    },
    {
      "epoch": 2.8971547125074095,
      "grad_norm": 0.35859549045562744,
      "learning_rate": 3.4564722194711304e-05,
      "loss": 0.121,
      "step": 19550
    },
    {
      "epoch": 2.9008595139300533,
      "grad_norm": 0.34782999753952026,
      "learning_rate": 3.332673071209271e-05,
      "loss": 0.1073,
      "step": 19575
    },
    {
      "epoch": 2.904564315352697,
      "grad_norm": 0.26977986097335815,
      "learning_rate": 3.2088739229474104e-05,
      "loss": 0.124,
      "step": 19600
    },
    {
      "epoch": 2.9082691167753407,
      "grad_norm": 0.2881321609020233,
      "learning_rate": 3.08507477468555e-05,
      "loss": 0.1152,
      "step": 19625
    },
    {
      "epoch": 2.9119739181979845,
      "grad_norm": 0.8215234875679016,
      "learning_rate": 2.9612756264236903e-05,
      "loss": 0.1287,
      "step": 19650
    },
    {
      "epoch": 2.915678719620628,
      "grad_norm": 0.3279147744178772,
      "learning_rate": 2.8374764781618303e-05,
      "loss": 0.1264,
      "step": 19675
    },
    {
      "epoch": 2.919383521043272,
      "grad_norm": 0.40147653222084045,
      "learning_rate": 2.7136773298999703e-05,
      "loss": 0.1141,
      "step": 19700
    },
    {
      "epoch": 2.923088322465916,
      "grad_norm": 0.3942028880119324,
      "learning_rate": 2.5898781816381103e-05,
      "loss": 0.1095,
      "step": 19725
    },
    {
      "epoch": 2.92679312388856,
      "grad_norm": 0.3015545606613159,
      "learning_rate": 2.4660790333762503e-05,
      "loss": 0.1023,
      "step": 19750
    },
    {
      "epoch": 2.9304979253112036,
      "grad_norm": 0.3415193259716034,
      "learning_rate": 2.3422798851143903e-05,
      "loss": 0.1381,
      "step": 19775
    },
    {
      "epoch": 2.9342027267338473,
      "grad_norm": 0.43014705181121826,
      "learning_rate": 2.223432702783005e-05,
      "loss": 0.1285,
      "step": 19800
    },
    {
      "epoch": 2.937907528156491,
      "grad_norm": 0.25482118129730225,
      "learning_rate": 2.0996335545211452e-05,
      "loss": 0.1177,
      "step": 19825
    },
    {
      "epoch": 2.9416123295791348,
      "grad_norm": 0.5080648064613342,
      "learning_rate": 1.975834406259285e-05,
      "loss": 0.1217,
      "step": 19850
    },
    {
      "epoch": 2.9453171310017785,
      "grad_norm": 0.3708829879760742,
      "learning_rate": 1.852035257997425e-05,
      "loss": 0.1253,
      "step": 19875
    },
    {
      "epoch": 2.9490219324244222,
      "grad_norm": 0.24025259912014008,
      "learning_rate": 1.7282361097355652e-05,
      "loss": 0.113,
      "step": 19900
    },
    {
      "epoch": 2.952726733847066,
      "grad_norm": 0.32314392924308777,
      "learning_rate": 1.6044369614737052e-05,
      "loss": 0.1144,
      "step": 19925
    },
    {
      "epoch": 2.9564315352697097,
      "grad_norm": 0.24961835145950317,
      "learning_rate": 1.4806378132118452e-05,
      "loss": 0.1142,
      "step": 19950
    },
    {
      "epoch": 2.9601363366923534,
      "grad_norm": 0.40055912733078003,
      "learning_rate": 1.3568386649499852e-05,
      "loss": 0.1115,
      "step": 19975
    },
    {
      "epoch": 2.963841138114997,
      "grad_norm": 0.25850722193717957,
      "learning_rate": 1.2330395166881252e-05,
      "loss": 0.1254,
      "step": 20000
    },
    {
      "epoch": 2.967545939537641,
      "grad_norm": 0.28233152627944946,
      "learning_rate": 1.1092403684262653e-05,
      "loss": 0.1179,
      "step": 20025
    },
    {
      "epoch": 2.9712507409602846,
      "grad_norm": 0.37920060753822327,
      "learning_rate": 9.854412201644053e-06,
      "loss": 0.1133,
      "step": 20050
    },
    {
      "epoch": 2.9749555423829284,
      "grad_norm": 0.331424742937088,
      "learning_rate": 8.616420719025453e-06,
      "loss": 0.1198,
      "step": 20075
    },
    {
      "epoch": 2.978660343805572,
      "grad_norm": 0.31454455852508545,
      "learning_rate": 7.378429236406854e-06,
      "loss": 0.1137,
      "step": 20100
    },
    {
      "epoch": 2.982365145228216,
      "grad_norm": 0.2119586020708084,
      "learning_rate": 6.1404377537882545e-06,
      "loss": 0.1192,
      "step": 20125
    },
    {
      "epoch": 2.9860699466508596,
      "grad_norm": 0.3054775595664978,
      "learning_rate": 4.9024462711696544e-06,
      "loss": 0.1346,
      "step": 20150
    },
    {
      "epoch": 2.9897747480735033,
      "grad_norm": 0.4345165491104126,
      "learning_rate": 3.6644547885510548e-06,
      "loss": 0.1168,
      "step": 20175
    },
    {
      "epoch": 2.993479549496147,
      "grad_norm": 0.45487624406814575,
      "learning_rate": 2.4264633059324555e-06,
      "loss": 0.1282,
      "step": 20200
    },
    {
      "epoch": 2.9971843509187908,
      "grad_norm": 0.3350710868835449,
      "learning_rate": 1.1884718233138557e-06,
      "loss": 0.12,
      "step": 20225
    }
  ],
  "logging_steps": 25,
  "max_steps": 20244,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3.475198831362048e+20,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
